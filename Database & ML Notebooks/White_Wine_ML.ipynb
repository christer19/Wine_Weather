{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "White_Wine_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhwv0JVk4OYf",
        "outputId": "67ddc5d7-7ee0-4620-f3b0-9488185a4a7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.0'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install psycopg2-binary\n",
        "!pip install keras-tuner\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sqlalchemy import create_engine\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [405 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,687 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,353 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,118 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,748 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,165 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [864 kB]\n",
            "Fetched 10.7 MB in 4s (2,865 kB/s)\n",
            "Reading package lists... Done\n",
            "Collecting psycopg2-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/1b/720b36697158113ca1b2221a8e96a470088ccf3770d182214689d1a96a07/psycopg2_binary-2.8.6-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.8.6\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=a1e93723fc5aade4f4501963c5224143f95c89b970b8dcbef8011a350253c657\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=ac0e4f901c0fb4cdb56a7f3fe51b69ed950caefd7dadba8f02ee7624a5b6ef9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA2YiP5p4diM",
        "outputId": "2dae6694-64bd-4516-9d16-1c64a117a404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# enter the following code to download a Postgres driver that will allow Spark to interact with Postgres:\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-03 01:30:21--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  3.77MB/s    in 0.3s    \n",
            "\n",
            "2020-11-03 01:30:21 (3.77 MB/s) - ‘postgresql-42.2.16.jar’ saved [1002883/1002883]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Dpxt-P4eci"
      },
      "source": [
        "# start a Spark session with an additional option that adds the driver to Spark:\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Wine_Weather\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufHy0SIvYK7W"
      },
      "source": [
        "##***White Wine Machine Learning Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5cDkhQuDASb",
        "outputId": "4f94ace7-0e2c-4f31-8139-b3f10fc33949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "#Read white wine sql table into a dataframe\n",
        "White_Soil_ML_df = pd.read_sql_table('white_soil_table', 'postgresql://postgres:postgres@database-1.cslpjur96f9r.us-east-2.rds.amazonaws.com:5432') \n",
        "White_Soil_ML_df.head() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>color</th>\n",
              "      <th>regions</th>\n",
              "      <th>country</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>confidence_index</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>silt_0-100cm</th>\n",
              "      <th>silt_100-200cm</th>\n",
              "      <th>soc_0-100cm</th>\n",
              "      <th>soc_100-200cm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santa Cruz Mountains</td>\n",
              "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
              "      <td>107658</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.5</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.7</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>324.85</td>\n",
              "      <td>283</td>\n",
              "      <td>128.55</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Pahlmeyer, Napa Valley Chardonnay, White, Napa...</td>\n",
              "      <td>111897</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>C+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Kongsgaard, The Judge Chardonnay, White, Napa ...</td>\n",
              "      <td>91591</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>B+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            appellation  ... soc_100-200cm\n",
              "0  Santa Cruz Mountains  ...            38\n",
              "1           Napa Valley  ...            27\n",
              "2          Sonoma Coast  ...            18\n",
              "3          Sonoma Coast  ...            18\n",
              "4           Napa Valley  ...            27\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NORZgQZO59u",
        "outputId": "e4a7375d-c367-49f7-e539-fce6d963c810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "White_Soil_ML_df.dtypes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appellation            object\n",
              "wine                   object\n",
              "wine_id                 int64\n",
              "color                  object\n",
              "regions                object\n",
              "country                object\n",
              "vintage                 int64\n",
              "is_primeurs              bool\n",
              "score                 float64\n",
              "confidence_index       object\n",
              "journalist_count        int64\n",
              "avgPrcpFebruary       float64\n",
              "avgTempFebruary         int64\n",
              "avgPrcpMarch          float64\n",
              "avgTempMarch            int64\n",
              "avgPrcpApril          float64\n",
              "avgTempApril            int64\n",
              "avgPrcpMay            float64\n",
              "avgTempMay              int64\n",
              "avgPrcpJune           float64\n",
              "avgTempJune             int64\n",
              "avgPrcpJuly           float64\n",
              "avgTempJuly             int64\n",
              "avgPrcpAugust         float64\n",
              "avgTempAugust           int64\n",
              "avgPrcpSeptember      float64\n",
              "avgTempSeptember        int64\n",
              "avgPrcpOctober        float64\n",
              "avgTempOctober          int64\n",
              "bdod_0-100cm          float64\n",
              "bdod_100-200cm          int64\n",
              "cec_0-100cm           float64\n",
              "cec_100-200cm           int64\n",
              "cfvo_0-100cm          float64\n",
              "cfvo_100-200cm          int64\n",
              "clay_0-100cm          float64\n",
              "clay_100-200cm          int64\n",
              "nitrogen_0-100cm      float64\n",
              "nitrogen_100-200cm      int64\n",
              "ocd_0-100cm           float64\n",
              "ocd_100-200cm           int64\n",
              "ocs_0-30cm              int64\n",
              "phh2o_0-100cm         float64\n",
              "phh2o_100-200cm       float64\n",
              "sand_0-100cm          float64\n",
              "sand_100-200cm          int64\n",
              "silt_0-100cm          float64\n",
              "silt_100-200cm          int64\n",
              "soc_0-100cm           float64\n",
              "soc_100-200cm           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yFuv7s1O59y",
        "outputId": "563cc983-1783-4678-f512-0bb1e1d46f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "White_Soil_ML_df[\"score\"].astype(int) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      92\n",
              "1      92\n",
              "2      92\n",
              "3      91\n",
              "4      97\n",
              "       ..\n",
              "727    87\n",
              "728    91\n",
              "729    93\n",
              "730    86\n",
              "731    88\n",
              "Name: score, Length: 732, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFRIEoeWO590"
      },
      "source": [
        "#Splitting score into good(1) and bad(0) and making it it's own column \"quality\"\n",
        "quality = []\n",
        "\n",
        "for x in White_Soil_ML_df[\"score\"]:\n",
        "  if x >= 91:\n",
        "    quality.append(1)\n",
        "  else:\n",
        "    quality.append(0)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUx-ic_fO592"
      },
      "source": [
        "White_Soil_ML_df[\"quality\"] = quality"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvx4qNPNO594",
        "outputId": "0685cdda-febd-4444-c0c9-79d6212f3a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "White_Soil_ML_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>color</th>\n",
              "      <th>regions</th>\n",
              "      <th>country</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>confidence_index</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>silt_0-100cm</th>\n",
              "      <th>silt_100-200cm</th>\n",
              "      <th>soc_0-100cm</th>\n",
              "      <th>soc_100-200cm</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santa Cruz Mountains</td>\n",
              "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
              "      <td>107658</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.50</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.70</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>324.85</td>\n",
              "      <td>283</td>\n",
              "      <td>128.55</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Pahlmeyer, Napa Valley Chardonnay, White, Napa...</td>\n",
              "      <td>111897</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>C+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.50</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.60</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.50</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.50</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.50</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.50</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Kongsgaard, The Judge Chardonnay, White, Napa ...</td>\n",
              "      <td>91591</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>B+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.50</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.60</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>Carneros</td>\n",
              "      <td>Truchard Vineyards, Chardonnay, White, Carneros</td>\n",
              "      <td>136966</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>87.68</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>62</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>68</td>\n",
              "      <td>0.116333</td>\n",
              "      <td>71</td>\n",
              "      <td>0.108710</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>76</td>\n",
              "      <td>160.40</td>\n",
              "      <td>161</td>\n",
              "      <td>215.4</td>\n",
              "      <td>233</td>\n",
              "      <td>30.15</td>\n",
              "      <td>25</td>\n",
              "      <td>216.10</td>\n",
              "      <td>219</td>\n",
              "      <td>60.15</td>\n",
              "      <td>36</td>\n",
              "      <td>117.25</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>5.80206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>317.75</td>\n",
              "      <td>340</td>\n",
              "      <td>408.60</td>\n",
              "      <td>401</td>\n",
              "      <td>57.90</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>Sonoma County</td>\n",
              "      <td>Peter Michael Winery, Belle Cote Chardonnay, W...</td>\n",
              "      <td>114819</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>91.76</td>\n",
              "      <td>C+</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>145.00</td>\n",
              "      <td>150</td>\n",
              "      <td>184.4</td>\n",
              "      <td>190</td>\n",
              "      <td>105.50</td>\n",
              "      <td>110</td>\n",
              "      <td>262.80</td>\n",
              "      <td>298</td>\n",
              "      <td>84.70</td>\n",
              "      <td>36</td>\n",
              "      <td>121.60</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>5.20206</td>\n",
              "      <td>5.7</td>\n",
              "      <td>352.40</td>\n",
              "      <td>337</td>\n",
              "      <td>371.65</td>\n",
              "      <td>346</td>\n",
              "      <td>110.95</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>Carneros</td>\n",
              "      <td>Kistler Vineyards, Hudson Vineyard Chardonnay,...</td>\n",
              "      <td>91298</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1995</td>\n",
              "      <td>False</td>\n",
              "      <td>93.90</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0.029286</td>\n",
              "      <td>63</td>\n",
              "      <td>0.428710</td>\n",
              "      <td>63</td>\n",
              "      <td>0.044333</td>\n",
              "      <td>68</td>\n",
              "      <td>0.060968</td>\n",
              "      <td>72</td>\n",
              "      <td>0.034667</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>160.40</td>\n",
              "      <td>161</td>\n",
              "      <td>215.4</td>\n",
              "      <td>233</td>\n",
              "      <td>30.15</td>\n",
              "      <td>25</td>\n",
              "      <td>216.10</td>\n",
              "      <td>219</td>\n",
              "      <td>60.15</td>\n",
              "      <td>36</td>\n",
              "      <td>117.25</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>5.80206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>317.75</td>\n",
              "      <td>340</td>\n",
              "      <td>408.60</td>\n",
              "      <td>401</td>\n",
              "      <td>57.90</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>Los Carneros</td>\n",
              "      <td>Joseph Phelps Vineyards, Carneros Chardonnay, ...</td>\n",
              "      <td>89562</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>86.86</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0.368800</td>\n",
              "      <td>52</td>\n",
              "      <td>0.087500</td>\n",
              "      <td>54</td>\n",
              "      <td>0.127000</td>\n",
              "      <td>56</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>63</td>\n",
              "      <td>0.062581</td>\n",
              "      <td>60</td>\n",
              "      <td>158.50</td>\n",
              "      <td>160</td>\n",
              "      <td>218.4</td>\n",
              "      <td>224</td>\n",
              "      <td>80.25</td>\n",
              "      <td>60</td>\n",
              "      <td>196.15</td>\n",
              "      <td>190</td>\n",
              "      <td>60.85</td>\n",
              "      <td>35</td>\n",
              "      <td>118.15</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>5.60206</td>\n",
              "      <td>6.2</td>\n",
              "      <td>353.05</td>\n",
              "      <td>365</td>\n",
              "      <td>362.85</td>\n",
              "      <td>391</td>\n",
              "      <td>63.50</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>Sonoma County</td>\n",
              "      <td>Ferrari-Carano, Fume Blanc, White, Sonoma County</td>\n",
              "      <td>73121</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>88.14</td>\n",
              "      <td>B+</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>145.00</td>\n",
              "      <td>150</td>\n",
              "      <td>184.4</td>\n",
              "      <td>190</td>\n",
              "      <td>105.50</td>\n",
              "      <td>110</td>\n",
              "      <td>262.80</td>\n",
              "      <td>298</td>\n",
              "      <td>84.70</td>\n",
              "      <td>36</td>\n",
              "      <td>121.60</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>5.20206</td>\n",
              "      <td>5.7</td>\n",
              "      <td>352.40</td>\n",
              "      <td>337</td>\n",
              "      <td>371.65</td>\n",
              "      <td>346</td>\n",
              "      <td>110.95</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>732 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              appellation  ... quality\n",
              "0    Santa Cruz Mountains  ...       1\n",
              "1             Napa Valley  ...       1\n",
              "2            Sonoma Coast  ...       1\n",
              "3            Sonoma Coast  ...       1\n",
              "4             Napa Valley  ...       1\n",
              "..                    ...  ...     ...\n",
              "727              Carneros  ...       0\n",
              "728         Sonoma County  ...       1\n",
              "729              Carneros  ...       1\n",
              "730          Los Carneros  ...       0\n",
              "731         Sonoma County  ...       0\n",
              "\n",
              "[732 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBb4KAPO596",
        "outputId": "4d5a3de0-7913-4082-de71-527ac11b54f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generate our categorical variable list\n",
        "White_Wine_cat = White_Soil_ML_df.dtypes[White_Soil_ML_df.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "# Check the number of unique values in each column\n",
        "White_Soil_ML_df[White_Wine_cat].nunique()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appellation          22\n",
              "wine                163\n",
              "color                 1\n",
              "regions               3\n",
              "country               1\n",
              "confidence_index      6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4mB3r6TO598",
        "outputId": "97201e8b-ae99-49d7-bb5b-a310270689b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the unique value counts to see if binning is required for Appellation\n",
        "Appellation_Count = White_Soil_ML_df.appellation.value_counts()\n",
        "Appellation_Count.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Napa Valley             229\n",
              "Carneros                112\n",
              "Russian River Valley     92\n",
              "Sonoma County            80\n",
              "Knights Valley           49\n",
              "Sonoma Coast             37\n",
              "Sonoma Mountain          29\n",
              "Santa Cruz Mountains     19\n",
              "Columbia Valley          17\n",
              "Eola-Amity Hills         13\n",
              "Name: appellation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg62g5TjO5-A",
        "outputId": "2fffb4f3-5914-4db6-9b03-f137b10a2dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Visualize the Appellation_Count\n",
        "Appellation_Count.plot.density()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f76775a2550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxedZn38c+VO/u+NmmWNl3SlpSuhC7gAMrSIiMVAS2I4gyKKD4zA7M8OIvjMMPMoDM6zgyiKCigj2wudJxKlU1FoDSlC03atGm6JM3e7Emz3tfzx31SYsja5s65l+v9et0vTs6W6xzSfHPO73d+R1QVY4wxZqoi3C7AGGNMcLHgMMYYMy0WHMYYY6bFgsMYY8y0WHAYY4yZlki3C5gNmZmZWlhY6HYZxhgTNHbv3t2sqlljLQuL4CgsLKS0tNTtMowxJmiIyInxltmtKmOMMdNiwWGMMWZaLDiMMcZMiwWHMcaYabHgMMYYMy0WHMYYY6bFgsMYY8y0hMVzHMY9fYNDvHCgnuqWHlbkp3JZUSYi4nZZxpjzYMFh/OZYczd3PL6Lqqbus/PetziThz6+lpS4KBcrM8acD7tVZfyisaOXWx55k7aeAR77VAkH79/MP25Zzs5jp/nkY2/RNzjkdonGmHNkwWFmnKry58/uo+1MPz+4Yz0fWJZNXLSHT2ws5L9uWcO+6jb+Zfsht8s0xpwjvwaHiGwWkQoRqRSR+8ZYHiMiTzvLd4pIoTM/Q0ReEZEuEfnvUdtcJCLvONv8p9gN84DzwoF6fnukmb/+4AUU5yb/3rLNF87lkxvn8/gbx3mnpt2dAo0x58VvwSEiHuAh4FqgGLhFRIpHrXYH0Kqqi4GvAw8683uBvwP+YoxdPwx8BihyPptnvnpzrgaGvHx1RwVFcxK5dd28Mdf5i01LyUiI5oHt5bNcnTFmJvjzimMdUKmqVaraDzwFbBm1zhbgcWf6OeBKERFV7VbV1/AFyFkiMhdIVtU3VVWBJ4AP+/EYzDT9fH8tVc3d/OWmpUR6xv7xSo6N4q7LF/FmVQulx1tmuUJjzPnyZ3DkAdUjvq5x5o25jqoOAu1AxiT7rJlknwCIyJ0iUioipU1NTdMs3Zyr779+goVZCVx1QfaE6926fh7pCdH89yuVs1SZMWamhGzjuKo+oqolqlqSlTXmu0jMDNtb3ca+6jZu31hIRMTETU/x0ZHcvrGQVyuaOHG6e8J1jTGBxZ/BcQooGPF1vjNvzHVEJBJIAU5Pss/8SfZpXPL0rmrioz3ceFH+5CsDH7u4gAiBp3ZVT76yMSZg+DM4dgFFIrJARKKBrcC2UetsA253pm8CXnbaLsakqnVAh4hscHpTfRJ4fuZLN9M1MOTlFwfquLo4m8SYqT1XmpMSyweWZfNsaQ0DQ14/V2iMmSl+Cw6nzeILwA7gIPCMqpaJyP0icr2z2qNAhohUAvcCZ7vsishx4GvAp0SkZkSPrM8D3wUqgaPAL/x1DGbqXjvSTFvPANevyp3Wdh8tyae5q4/XKpv9VJkxZqb5dcgRVd0ObB8170sjpnuBm8fZtnCc+aXAhTNXpZkJ/7OvluTYSP6gaHrtSZcvzSIpJpL/3V/H+5fO8VN1xpiZFLKN42b29A0O8cvyBq69cC7RkdP7kYqJ9HD18mx2lNXbMCTGBAkLDnPedh1rpatvkE0XTtwFdzwfWplLZ+8grx2x21XGBAMLDnPeXj7USHRkBBsXZp7T9pcuziQlLor/faduhiszxviDBYc5b69WNLJxYQZx0Z5z2j46MoIrlmbxakUTQ95xO9UZYwKEBYc5L8ebu6lq7ub9S8/vIcsPLJtDS3c/+2raZqgyY4y/WHCY8/JqRSMAV5xnj6jLl2QRIfDKocaZKMsY40cWHOa8/O7oaealx1OYmXBe+0mNj+ai+Wm8dNCCw5hAZ8FhzpnXq+w63sKGhekzsr8PLMumvK6D+vbeyVc2xrjGgsOcs4qGTtp6Bli/YKIBjafusiW+Xlm/s6fIjQloFhzmnL1Z5RuPcv0MXXFckJNMekI0vztqwWFMILPgMOdsZ1UL+Wlx5KfFz8j+IiKEjQszeOPoaSYY69IY4zILDnNOvF5l57HTbFg4M7ephm1clEFdey/Hmu0dHcYEKgsOc06ONHbR2jPA+gUzc5tq2KWLnXaOoxO9lsUY4yYLDnNO3nLeFT5TDePDCjPiyU2J5XVrIDcmYFlwmHOy52QrmYnRFKTHzeh+RYRLFmfyRtVpvDb8iDEByYLDnJO91W2sLkjD9yLGmbVhYQZtPQMcaeya8X0bY86fBYeZtvaeAaqaulkzL9Uv+7+4MA2AXc7tMGNMYLHgMNO21xmIcE2Bf4JjXno8WUkxlFpwGBOQLDjMtO092YYIrMhP8cv+RYR1hensOt7ql/0bY86PBYeZtj3VrSyZk0RSbJTfvkdJYRqn2s5wqu2M376HMebcWHCYaVFVp2HcP7ephl1c6Hs+xG5XGRN4LDjMtBw/3UNbz4DfGsaHLctJIjEm0hrIjQlAFhxmWvZW+9odVvs5OCI9EayZl0qptXMYE3AsOMy07KtuJz7aQ9GcJL9/r4sL06lo6KS9Z8Dv38sYM3UWHGZaymrbKZ6bjCdi5h/8G62kMA1V2H3SblcZE0gsOMyUeb1KeW0Hy3OTZ+X7rSlIwxMh7D5ht6uMCSQWHGbKjp/uprt/iOV5/nl+Y7S4aA/LcpLYW902K9/PGDM1Fhxmyg7UdgDM2hUHwJp5qeyrbmfIBjw0JmBYcJgpKzvVTrQnYlYaxoetKUijq2+Qo0024KExgcKvwSEim0WkQkQqReS+MZbHiMjTzvKdIlI4YtkXnfkVIrJpxPx7RKRMRA6IyI9EJNafx2DeVVbbwdKcJKIjZ+/vjeFuv3tOWjuHMYHCb78BRMQDPARcCxQDt4hI8ajV7gBaVXUx8HXgQWfbYmArsBzYDHxTRDwikgf8CVCiqhcCHmc942eqyoHa9lm9TQWwICOBlLgoa+cwJoD480/HdUClqlapaj/wFLBl1DpbgMed6eeAK8X3goctwFOq2qeqx4BKZ38AkUCciEQC8UCtH4/BOE61naGtZ2DWGsaHRUQIqwpS2XPSgsOYQOHP4MgDqkd8XePMG3MdVR0E2oGM8bZV1VPAvwEngTqgXVV/6Zfqze8pcxrGL5zlKw7wDd9+uKGTrr7BWf/expj3CqrGcRFJw3c1sgDIBRJE5LZx1r1TREpFpLSpqWk2ywxJZafaiRBYluNCcMxLxauwv8auOowJBP4MjlNAwYiv8515Y67j3HpKAU5PsO1VwDFVbVLVAeAnwCVjfXNVfURVS1S1JCsrawYOJ7wdqO1g8ZxE4qI9s/69h0fitdtVxgQGfwbHLqBIRBaISDS+Ruxto9bZBtzuTN8EvKyq6szf6vS6WgAUAW/hu0W1QUTinbaQK4GDfjwG4yirbWd57uy2bwxLjY9mYWaCNZAbEyAi/bVjVR0UkS8AO/D1fnpMVctE5H6gVFW3AY8CT4pIJdCC00PKWe8ZoBwYBO5W1SFgp4g8B7ztzN8DPOKvYzA+rd39NHT0ccHc2Xt+Y7TVBan85kgzqorvbwZjjFv8FhwAqrod2D5q3pdGTPcCN4+z7QPAA2PM/3vg72e2UjORQ/WdACx1oX1j2Jp5qfxkzylOtZ0hPy3etTqMMUHWOG7ccbjBCY5s96441sxLA6ydw5hAYMFhJnWovpOUuCiyk2Ncq2FpThIxkRHWzmFMALDgMJOqqPcNNeJm20KUJ4KV+Sk29IgxAcCCw0xIVTnc0MWyHPduUw1bXZDKgdoO+ge9bpdiTFiz4DATOtV2hq6+QZa42L4xbFVBKv2DXg7Vd7hdijFhzYLDTKjC6VEVKFccgLVzGOMyCw4zoQqnR9WSAAiOvNQ4MhNj2Gs9q4xxlQWHmVBFfSe5KbEkx0a5XQoiwuqCVLviMMZlFhxmQhX1nSwNgKuNYWvmpVLV3E17z4DbpRgTtiw4zLgGhrwcbepy9Ynx0YbbOfbZSLnGuMaCw4zrWHM3A0PK0pxEt0s5a2V+CiLWQG6Mmyw4zLjOjlGVHThXHEmxUSzOSrTgMMZFFhxmXBX1HXgihEVzEtwu5fcMN5D7RuA3xsw2Cw4zror6LhZmJhATOfsvb5rI6nmptHT3U91yxu1SjAlLFhxmXBUNHQHx/MZoZ98IWG3jVhnjBgsOM6auvkGqW86wLACGGhltaXYSsVE2Uq4xbrHgMGM6MvwOjgC84oj0RLAiL8WCwxiXWHCYMVXUB25wgO92VZmNlGuMKyw4zJgO1XcSH+2hIEBf07q6II3+QS8H62ykXGNmmwWHGdPhhk6KspOIiHDv5U0TWT3PRso1xi0WHGZMFfWdLM0OnCfGR8tNiSUrKcaCwxgXWHCY92jq7ON0d39AjVE1mo2Ua4x7LDjMexxuCJyXN01kdUEqx5q7aevpd7sUY8KKBYd5j0MB3qNq2JqzI+W2u1yJMeHFgsO8R0V9BxkJ0WQmxrhdyoRWDI+Ua28ENGZWWXCY9wi0lzeNJyk2iqI5iey1oUeMmVUWHOb3eL3K4YauoAgOgFX5NlKuMbPNgsP8nurWHs4MDLE0AMeoGsvqeam09gxwsqXH7VKMCRsWHOb3BEvD+LDhkXKtW64xs8eCw/yew05wLAmSK46l2UnERXnYYw3kxswavwaHiGwWkQoRqRSR+8ZYHiMiTzvLd4pI4YhlX3TmV4jIphHzU0XkORE5JCIHRWSjP48h3Bxq6KQgPY6EmEi3S5kSGynXmNnnt+AQEQ/wEHAtUAzcIiLFo1a7A2hV1cXA14EHnW2Lga3AcmAz8E1nfwDfAF5Q1WXAKuCgv44hHPmGGgncJ8bHsnpeKuW1HfQNDrldijFhwZ9XHOuASlWtUtV+4Clgy6h1tgCPO9PPAVeKiDjzn1LVPlU9BlQC60QkBbgMeBRAVftV1f7UnCF9g0Mca+4O+CfGR1tdkEr/kJeDdZ1ul2JMWJhScIjIT0TkOhGZTtDkAdUjvq5x5o25jqoOAu1AxgTbLgCagO+JyB4R+a6IJIxT850iUioipU1NTdMoO3wdbexmyKtB0zA+7GwD+Ul7nsOY2TDVIPgmcCtwRET+VUSW+rGmiUQCa4GHVXUN0A28p+0EQFUfUdUSVS3JysqazRqDVkWD790WwRYcc1NimWMj5Roza6YUHKr6oqp+HN8v7ePAiyLyuoj8kYhEjbPZKaBgxNf5zrwx1xGRSCAFOD3BtjVAjarudOY/59RkZkBFfRdRHmFB5pgXcQHLRso1ZnZN+daTiGQAnwI+DezB10i9FvjVOJvsAopEZIGIRONr7N42ap1twO3O9E3Ay+p7BHgbsNXpdbUAKALeUtV6oHrEFc+VQPlUj8FMrKK+g0VZiUR5gq+X9up5qRw/3UNrt42Ua4y/TanPpYj8FFgKPAl8SFXrnEVPi0jpWNuo6qCIfAHYAXiAx1S1TETuB0pVdRu+Ru4nRaQSaMEXLjjrPYMvFAaBu1V1uMvM/wF+6IRRFfBH0z5qM6aK+k4uXpDudhnn5KJ5aQDsPtHKVcXZLldjTGibamf976jq9pEzRCTG6fVUMt5GzjbbR8370ojpXuDmcbZ9AHhgjPl7gXG/pzk3Hb0D1Lb3Bl37xrBVBalEeyLYdbzFgsMYP5vqPYl/GmPeGzNZiHHX8BPjwdYVd1hslIcV+SnsOt7idinGhLwJrzhEJAdfN9g4EVkDiLMoGYj3c21mFr07RlVwPfw3UklhGo+9dozegSFiozyTb2CMOSeT3arahK9BPB/42oj5ncBf+6km44JD9R0kxUaSmxLrdinnbF1hOt/+dRV7q9vYsDDD7XKMCVkTBoeqPg48LiI3quqPZ6km4wLfUCNJ+B7cD04Xzfc1kJceb7HgMMaPJrtVdZuq/gAoFJF7Ry9X1a+NsZkJMqrKofpOrl+V63Yp5yU1Ppql2Um8ddyeIDfGnya7VTX8JFiivwsx7qlr76WzdzBoG8ZHKilM4/m9tQx5FU9E8F49GRPIJrtV9W3nv/8wO+UYN1SEQMP4sIsL0/nhzpMcqu9geW6K2+UYE5KmOsjhV0QkWUSiROQlEWkSkdv8XZyZHWd7VAXJy5smMvwA465j1i3XGH+Z6nMc16hqB/CH+MaqWgz8pb+KMrOror6D3JRYUuLHG3YseOSlxpGbEsuuE9bOYYy/TDU4hm9pXQc8q6rtfqrHuOBQfWfQPjE+losXpLOzqgXfsGfGmJk21eD4uYgcAi4CXhKRLKDXf2WZ2TIw5OVoU1dItG8Mu2RRBs1dfVQ2drldijEhaarDqt8HXAKUqOoAvvdgjH6bnwlCVU3dDAxpSPSoGnbJokwAXj962uVKjAlNUx3kEGAZvuc5Rm7zxAzXY2bZofrgfHnTRArS48lPi+P1o83cfkmh2+UYE3KmOqz6k8AiYC8wPLy5YsER9CrqO4mMEBZlhdajOpcsymBHWYM9z2GMH0z1iqMEKFZrbQw5FfWdLMxKIDoy+F7eNJFLF2fyTGkN5bUdrMi35zmMmUlT/W1xAMjxZyHGHYfqO1kWQg3jwzY6Y1W9frTZ5UqMCT1TDY5MoFxEdojItuGPPwsz/tfRO8CptjMh1b4xbE5yLIvnJFoDuTF+MNVbVV/2ZxHGHcH+8qbJXLIog+d219A/6A25W3HGuGmq3XF/je+J8Shnehfwth/rMrPg3Zc3hW5w9PQPsbe6ze1SjAkpUx2r6jPAc8C3nVl5wM/8VZSZHRX1nSTFRJKXGud2KX6xcVEmngjh14cb3S7FmJAy1ev3u4FLgQ4AVT0CzPFXUWZ2VNR3siQnuF/eNJGUuCjWzkvl1Yomt0sxJqRMNTj6VLV/+AvnIUDrmhvEfC9v6gjZ21TDrlg6h7LaDho7bYQcY2bKVIPj1yLy10CciFwNPAv8j//KMv5W03qGjt5BlueGXlfckS5fkgXAr+2qw5gZM9XguA9oAt4BPgtsB/7WX0UZ/yur9Q01Ujw3tINjeW4yWUkxvHrYgsOYmTKl7riq6hWRnwE/U1X7FxgCyus6iBBC8uG/kUSEK5ZksaOsnsEhL5Ee65ZrzPma8F+R+HxZRJqBCqDCefvfl2anPOMv5bXtLMxKJC7a43YpfnfF0jl09A5at1xjZshkf37dg6831cWqmq6q6cB64FIRucfv1Rm/Ka/tCPnbVMPeV5RJZITw4kHrlmvMTJgsOD4B3KKqx4ZnqGoVcBvwSX8WZvyntbuf2vbekG8YH5YSF8XGRRm8cKDO3gpozAyYLDiiVPU9o8Q57RzB/4LqMFVe5zSMh0lwAGxansPx0z0cbrC3AhpzviYLjv5zXAaAiGwWkQoRqRSR+8ZYHiMiTzvLd4pI4YhlX3TmV4jIplHbeURkj4j8fLIazHuVh0mPqpGuKc5GBHaU1btdijFBb7LgWCUiHWN8OoEVE20oIh7gIeBaoBi4RUSKR612B9CqqouBrwMPOtsWA1uB5cBm4JvO/ob9KXBwaodoRiuv6yAnOZaMxBi3S5k1c5JjWTsvjRcOWHAYc74mDA5V9ahq8hifJFWd7FbVOqBSVaucp86f4r3vKd8CPO5MPwdcKb7xL7YAT6lqn9O+UunsDxHJB64DvjudAzXvKqttD6vbVMM2Lc+mvK6D6pYet0sxJqj5s1N7HlA94usaZ96Y66jqINAOZEyy7X8AfwV4J/rmInKniJSKSGlTkz16Mqx3YIijTd1h0zA+0qblvneR2VWHMecnqJ6GEpE/BBpVdfdk66rqI6paoqolWVlZs1BdcKio72TIq2HVvjFsfkYCF+Yls21frdulGBPU/Bkcp4CCEV/nO/PGXMcZODEFOD3BtpcC14vIcXy3vj4gIj/wR/GhKhx7VI304dV5vHOqncrGTrdLMSZo+TM4dgFFIrJARKLxNXaPft3sNuB2Z/om4GX1dbTfBmx1el0tAIqAt1T1i6qar6qFzv5eVtXb/HgMIaestp2kmEgK0uLdLsUV16/OJULgZ3vsqsOYc+W34HDaLL4A7MDXA+oZVS0TkftF5HpntUeBDBGpBO7FN5giqloGPAOUAy8Ad6vqkL9qDSfvnOqgODeZiIjQfAfHZOYkxfK+oix+tvcUXq89DGjMuZjqO8fPiapuxzeS7sh5Xxox3QvcPM62DwAPTLDvV4FXZ6LOcNE/6OVgbQefurTQ7VJcdcOaXO55eh+7T7ZycWG62+UYE3SCqnHcnJ+K+k76h7yszE9xuxRXXVOcQ1yUh5+8XeN2KcYEJQuOMLL/lG902JV5qS5X4q6EmEiuWzmXbXtr6ewdcLscY4KOBUcY2V/dTlp8FAXpcW6X4rrbNsynu3+In+0Z3dHPGDMZC44wsq+mjRX5qfgezg9vq/JTuDAvmR+8edJGzDVmmiw4wsSZ/iGONHaxKszbN4aJCLetn09FQyelJ1rdLseYoGLBESbK69oZ8ior88O7fWOk61fnkhQbyZNvnHC7FGOCigVHmNhX3Q4Q9j2qRoqPjuTmiwrY/k4dp9rOuF2OMUHDgiNM7K9pIzs5huzkWLdLCSh3/MECAL772yqXKzEmeFhwhIn9p9rtNtUY8lLj2LI6j6feqqale9J3kxljsOAICx29A1Q1dVvD+DjuunwhZwaG+P7rx90uxZigYMERBvac9D34t2ZemsuVBKai7CQ2L8/hsdeO2VWHMVNgwREGdp9oJUJgVYHdqhrPn1+zhJ7+Qb75SqXbpRgT8Cw4wsDbJ1pZlpNMYoxfx7QMakXZSXxkbT5PvHmCWuthZcyELDhC3JBX2XOylYvm222qyfzZVUWg8OALh9wuxZiAZsER4irqO+nuH6Kk0IJjMvlp8dx1+UKe31vL60eb3S7HmIBlwRHidp/0Daex1hrGp+Tz719MQXocX3q+jP5Br9vlGBOQLDhC3NsnWpmTFEN+mo2IOxWxUR6+/KHlVDZ28R17KNCYMVlwhLjdJ3ztGzYi7tRdeUE2116Yw3+8eJjy2g63yzEm4FhwhLDGzl5OtvRYw/g5eOCGFaTGR3PP03vpHbDX3RszkgVHCNt1zNe+YcExfekJ0XzlppVUNHRaLytjRrHgCGFvVDWTEO1hRZ4NNXIu3r90Dp+6pJDv/e442/bVul2OMQHDgiOEvVnVwsUL0on02P/mc/XXH7yAiwvT+Kvn9ll7hzEO+40Soho7e6ls7GLjwgy3Swlq0ZERPPTxtaTERfGZJ0pp7Oh1uyRjXGfBEaJ2VrUAsMGC47zNSYrlO58sobWnn9u/t4vO3gG3SzLGVRYcIeqNqtMkxUSyPDfZ7VJCwsr8VB6+7SKONHTy2Sd30zdoPa1M+LLgCFFvHj1t7Rsz7PIlWXzlppW8fvQ0n/vB2xYeJmzZb5UQ1NDRS1Vzt7Vv+MFH1ubzwA0X8vKhRgsPE7YsOELQG0dPA9a+4S8fXz+ff75hBS8fauSuJ3fbA4Im7FhwhKBfH24iPSHa2jf86Nb18/jnG1bwSkUTf/z9XXT1DbpdkjGzxq/BISKbRaRCRCpF5L4xlseIyNPO8p0iUjhi2Red+RUissmZVyAir4hIuYiUicif+rP+YOT1Kr853MRlRZlERNj4VP506/p5fO2jq9h5rIVbv/Mmp7v63C7JmFnht+AQEQ/wEHAtUAzcIiLFo1a7A2hV1cXA14EHnW2Lga3AcmAz8E1nf4PAn6tqMbABuHuMfYa1A7XtnO7u5/KlWW6XEhY+sjafRz5xERX1ndz87Tc4ZW8PNGHAn1cc64BKVa1S1X7gKWDLqHW2AI87088BV4pvGNctwFOq2qeqx4BKYJ2q1qnq2wCq2gkcBPL8eAxB59cVTYjAZUUWHLPlyguyefKO9TR19nHTw69T2djpdknG+JU/gyMPqB7xdQ3v/SV/dh1VHQTagYypbOvc1loD7JzBmoPerw83sSIvhYzEGLdLCSvrFqTz9J0bGRhSbv7WG+yrbnO7JGP8Jigbx0UkEfgx8GeqOuYAQiJyp4iUikhpU1PT7BbokvaeAd4+2crlS+xqww3Fucn8+HMbSYyN5NbvvMnrlfb6WROa/Bkcp4CCEV/nO/PGXEdEIoEU4PRE24pIFL7Q+KGq/mS8b66qj6hqiaqWZGWFxy/SVyoa8SpcsXSO26WErfkZCTx31yXkpcXxqe/tYkdZvdslGTPj/Bkcu4AiEVkgItH4Gru3jVpnG3C7M30T8LKqqjN/q9PragFQBLzltH88ChxU1a/5sfagtKOsnjlJMawpSHW7lLCWnRzLM5/dyPK8ZD73g908W1o9+UbGBBG/BYfTZvEFYAe+RuxnVLVMRO4Xkeud1R4FMkSkErgXuM/Ztgx4BigHXgDuVtUh4FLgE8AHRGSv8/mgv44hmPQODPFqRRPXLM+2brgBIDU+mh/csZ5LF2fyl8/t59HXjrldkjEzJtKfO1fV7cD2UfO+NGK6F7h5nG0fAB4YNe81wH4rjuG3R5o5MzDEpuU5bpdiHAkxkXz39hLueXov//jzctp6+rn36iX2/ncT9PwaHGb2vHCgnuTYSBtmJMDERHr4r1vWkhTzDv/1ciXtZwb48oeW21WhCWoWHCFgYMjLS4cauPKCbKJsNNyA44kQ/vXGFaTGR/Ht31QxMOTlgQ+vsPAwQcuCIwT89kgTbT0DfHDFXLdLMeMQEe67dhnRkRH818uVDHmVf/3ISgsPE5QsOELAT/fUkhYfZc9vBDgR4d6rlxAhwjdeOsKQF75y00o8Fh4myFhwBLnO3gF+WVbPzSX5REfabapAJyLcc/USPBHC1351mCGvl3+7eZW9cMsEFQuOILejrIG+QS83rLEhu4LJn1xZhCdC+OqOCoYUvv5RCw8TPCw4gtxP99RQkB7H2nlpbpdipunu9y/2NZz/4hBeVf7jY6utc4MJChYcQex4cze/qzzNPVfZswHB6q7LF+ER4YHtB/F6lf+8ZY2Fhwl49hMaxH648wSREcLWdQWTr2wC1mcuW8jfXncBvzhQzxf+39v0D3rdLsmYCVlwBKnegSGe3V3DNcuzyU6Odbscc54+/QcL+fsPFbOjrIG7LTxMgLPgCFI/319HW88At22Y71LbkPMAAA3dSURBVHYpZob80aULuH/Lcn5V3sDnfrCbvsEht0syZkwWHEFIVXnstWMsnpPIRhtiJKR8cmMh//ThC3npUCN3Pbmb3gELDxN4LDiC0KuHmyiv6+Czly20RvEQdNuG+fzzDSt4paKJz1p4mABkwRGEvvlKJXmpcXzYnt0IWbeun8eDN67gN0ea+MwTpRYeJqBYcASZnVWn2XW8lTsvW2jdNkPcxy6ex1duXMlrlc18+vFSevoH3S7JGMCCI6ioKl/dUUFWUgwfu9i64IaDm0sK+LebVvH60WZu/c5OWrv73S7JGAuOYLKjrIHSE63ce/USYqM8bpdjZsmNF+Xz8G0XUV7XwY3fep2a1h63SzJhzoIjSPQNDvHgC4dYPCeRmy/Kd7scM8s2Lc/hyT9eR1NnHzc+/DqH6jvcLsmEMQuOIPHwq0c51tzN3153gQ2GF6bWL8zg2bs2AnDzw2/w0sEGlysy4cp+AwWBysYuvvnKUa5flcsVS+e4XY5x0bKcZH76+UuZnxnPp58o5aFXKlFVt8syYcYGOQxw/YNe7n1mL3HRHv7uD4vdLscEgNzUOJ797CX83x/v56s7Kiiv6+DBG1eSGBP8/5xVlZrWM1Q2dVHV1E11Sw+tPf209QzQOzCEJ0LwRAjJcVHMSYohOzmWxVmJLJubRF5qnD3XNEuC/yctxH11xyH217TzrdsuIispxu1yTICIi/bwja2rKc5N5isvHOLAqXa+sXUNqwtS3S5t2iobO3m1oonS462Unmiluavv7LLEmEjSE6JJi48iJspD/6CXQa8vXF7t6KW7/93nW1Liori4MJ0NC9PZuCiD4rnJFiR+YsERwLbtq+U7vz3GJzbMZ/OFOW6XYwKMiHDX5YtYU5DKvc/s48aHX+eeq4q46/JFAd8Odrihk//dX8f2d+o40tgFQEF6HH9QlMna+Wksy0liYWYC6QnRE/7y7+gd4EhDJ4fqO3mnpp2dx1p40Wn7yU2J5ZrlOVxTnM26BekBf06CiYTD/dGSkhItLS11u4xp2X2ihVu+s5PVBak8ecc6YiKt+60ZX/uZAf7mp+/w8/11XDA3mX/68IVcND9wXu6lqlQ0dLJ9fx3bD9RT2diFCFxcmM51K+ZydXE2ualxM/K96tt7+c2RJn5Z1sBvjzTRN+glIyGaD63K5YY1eazMT7ErkSkQkd2qWjLmMguOwLP7RAu3P7aLrKQYfvK5S0hLiHa7JBMEVJVfHKjn/v8pp76jl4+W5PNnVy2ZsV/I51LPwbpOtr9Tx/YDdVQ1dRMhsG6BLyw2Lc9hjp9fCdDTP8hvDjexbV8tLx5spH/Qy8KsBD6yJo8tq/MoSI/36/cPZhYcQRQcrx1p5rNPljInOZYffWYDOSn2rg0zPV19g/znS0f43u+OIQi3rp/HXZcvmpWfJVVlf007O8rq+cWBeo41+8Jiw8IMPuiEhVttde1nBtj+Th0/3XOKt461ALCuMJ0ta3K5bsVcUuPtD7SRLDiCIDhUlUdfO8Y/bz9I0Zwknrhjnb2gyZyXmtYeHnqlkmdLawC4Znk2H18/nw0LM/BEzNytmv5BL6XHW9hRVs8vyxuoa+/FEyFsPBsW2WQkBlbHjuqWHp7fe4qf7a2lsrGLKI9w+ZI5fHhNLlddkG0jM2DBEfDBUdPawxd/8g6/PdLM5uU5/PtHV5EQAl0rTWCobunhyTdP8ExpNW09A2QmRnN1cQ6XL8mipDCNzGn+Uu/oHeBQXSelJ1p44+hpdh1voXfAS2xUBJcVZXHN8hyuXDYnKG6xqipltR08v/cU2/bV0tDRR2JMJJuW53DdyhwuWZQZtiFiwRGgwdHW08+3f1PF9393HBG479pl3LZ+PhEz+NegMcN6B4b4VXkDL5TV8+qhxrNdWQvS41iYmciCzAQyE6NJjIkkPjqSAa+XvgEvnb2D1Hf0Utd+hqNNXVS3nDm7z6XZSWxclMElizJ4X1Em8dHB+wfPkFd5s+o0P9tzihcO1NPZN0hclIf3FWVy9QXZXLE0y+9tMoHEgiOAgmP4L5wfvXWS5/fW0t0/yPWrcvnLTUvJT7OGOjM7+gaHOHCqndLjrew/1c7x5m5OnO6hq2/sodszEqKZmxrL/PQEinOTKc5NZkVeyrSvVoJF3+AQb1a18GJ5Ay8dbKC2vReAhZkJrF+YzoaFGaydl0Z+Wug+dOhacIjIZuAbgAf4rqr+66jlMcATwEXAaeBjqnrcWfZF4A5gCPgTVd0xlX2Oxc3gUFXq2nvZX9PO60ebeflQIzWtZ4iJjOC6FXO58/KFLMtJdqU2Y0brH/TS3TdId/8gUZ4IYiIjiIv2hHV3cFWlvK6D31U2s7OqhbeOtdDpBGxKXBTFc5NZnpvMkpwkCjMSKMyIJyspJugDxZXgEBEPcBi4GqgBdgG3qGr5iHU+D6xU1btEZCtwg6p+TESKgR8B64Bc4EVgibPZhPscy0wGh6oy5FUGhpT+IS89/YO0nxmgvWeA9jMDtJ0Z4FTrGapbe6hpPUNVUxfNXb53KMRFebh0cSYfWDaH61bMJSU+akZqMsbMniGvcrCug73VbZTVdlBe287B+k76B71n14mP9pCfFsecpFiykmLITIwmKymGtPhokmIjSYiJJNH5JMREEhflIdIjRHkiiPZEBMTt6omCw583JNcBlapa5RTxFLAFGPlLfgvwZWf6OeC/xRfTW4CnVLUPOCYilc7+mMI+Z8yV//4qXX2DDAwpA4Ne+od8n8myVgRykmPJT4vjiqVzWJGXwsr8FC6Ymxy2DW3GhApPhHBhXgoX5qWcnTc45OVU2xmOn+7hxOlujjf3UN3aQ3NXH8ePd9PU2UffiGCZyveIcoIkyhNBhAgiECEgDE/7wmV4WgQEZ74znZEQwzPOiMozyZ/BkQdUj/i6Blg/3jqqOigi7UCGM//NUdsOv2B7sn0CICJ3AncCzJs375wOYN2CDFT17P+8qEghenjaE0GUR4iPjiQlLursJzU+iuzkWKIjbXgDY8JFpCeC+RkJzM9IALLes1xV6eobpLV7gC7nVmBX7yBdfb5P38DQ2bsYA0NeBoeUAecP1YEhL0NeAEUVvOr7r+KbZsT06PlJsf75FR+8XSAmoaqPAI+A71bVuezjXz6yYkZrMsaEJxEhKTaKpNjQuD3tzz+LTwEjX4yd78wbcx0RiQRS8DWSj7ftVPZpjDHGj/wZHLuAIhFZICLRwFZg26h1tgG3O9M3AS+rr7V+G7BVRGJEZAFQBLw1xX0aY4zxI7/dqnLaLL4A7MDXdfYxVS0TkfuBUlXdBjwKPOk0frfgCwKc9Z7B1+g9CNytqkMAY+3TX8dgjDHmvewBQGOMMe8xUXdc6/pjjDFmWiw4jDHGTIsFhzHGmGmx4DDGGDMtYdE4LiJNwAk/7T4TaPbTvoONnYt32bl4l50Ln2A7D/NV9b2PwRMmweFPIlI6Xs+DcGPn4l12Lt5l58InlM6D3aoyxhgzLRYcxhhjpsWC4/w94nYBAcTOxbvsXLzLzoVPyJwHa+MwxhgzLXbFYYwxZlosOIwxxkyLBcc0iMjNIlImIl4RKRm17IsiUikiFSKyacT8zc68ShG5b/arnh3hcpzDROQxEWkUkQMj5qWLyK9E5Ijz3zRnvojIfzrnZr+IrHWv8pklIgUi8oqIlDv/Nv7UmR+O5yJWRN4SkX3OufgHZ/4CEdnpHPPTzishcF4b8bQzf6eIFLpZ/7Soqn2m+AEuAJYCrwIlI+YXA/uAGGABcBTfsO8eZ3ohEO2sU+z2cfjhvITFcY465suAtcCBEfO+AtznTN8HPOhMfxD4Bb7XQG8Adrpd/wyeh7nAWmc6CTjs/HsIx3MhQKIzHQXsdI7xGWCrM/9bwOec6c8D33KmtwJPu30MU/3YFcc0qOpBVa0YY9EW4ClV7VPVY0AlsM75VKpqlar2A08564aacDnOs1T1N/jeITPSFuBxZ/px4MMj5j+hPm8CqSIyd3Yq9S9VrVPVt53pTuAgkEd4ngtV1S7nyyjno8AHgOec+aPPxfA5eg64UkRklso9LxYcMyMPqB7xdY0zb7z5oSZcjnMy2apa50zXA9nOdFicH+dWyxp8f2mH5bkQEY+I7AUagV/huxJvU9VBZ5WRx3v2XDjL24GM2a343PjtDYDBSkReBHLGWPQ3qvr8bNdjgpOqqoiETV93EUkEfgz8map2jPzDOZzOhfreVLpaRFKBnwLLXC7JLyw4RlHVq85hs1NAwYiv8515TDA/lEx0/OGkQUTmqmqdc/ul0Zkf0udHRKLwhcYPVfUnzuywPBfDVLVNRF4BNuK7HRfpXFWMPN7hc1EjIpFACnDalYKnyW5VzYxtwFanl8QCoAh4C9gFFDm9KqLxNYBtc7FOfwmX45zMNuB2Z/p24PkR8z/p9CjaALSPuI0T1Jx78o8CB1X1ayMWheO5yHKuNBCROOBqfG0+rwA3OauNPhfD5+gm4GV1WsoDntut88H0AW7Ad4+yD2gAdoxY9jf47mdWANeOmP9BfD1NjuK73eX6cfjp3ITFcY443h8BdcCA8zNxB7770y8BR4AXgXRnXQEecs7NO4zokRfsH+B9+BqA9wN7nc8Hw/RcrAT2OOfiAPAlZ/5CfH9IVgLPAjHO/Fjn60pn+UK3j2GqHxtyxBhjzLTYrSpjjDHTYsFhjDFmWiw4jDHGTIsFhzHGmGmx4DDGGDMtFhzGGGOmxYLDGGPMtPx/7BvbnlJZsEcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pTwMSKWO5-C"
      },
      "source": [
        "# Determine which values to replace for \n",
        "Appellation_Bin =  list(Appellation_Count[Appellation_Count < 200].index)\n",
        "# Replace in DataFrame\n",
        "for type in Appellation_Bin:\n",
        "    White_Soil_ML_df.appellation = White_Soil_ML_df.appellation.replace(type,\"Other\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55cb4HnEO5-G",
        "outputId": "5c9dc0a5-a4eb-483d-d822-cb1ca17a40d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check to make sure binning was successful for Appellation\n",
        "White_Soil_ML_df.appellation.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other          503\n",
              "Napa Valley    229\n",
              "Name: appellation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoMqlVkUO5-I"
      },
      "source": [
        "# White_Soil_ML_df[White_Soil_ML_df.appellation != 'Other']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCf6JriO5-L",
        "outputId": "3ad0b2bb-e524-46f9-fa6e-b45cdb76071b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# Create the OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit the encoder and produce encoded DataFrame\n",
        "White_Wine_encode_df = pd.DataFrame(enc.fit_transform(White_Soil_ML_df[White_Wine_cat]))\n",
        "\n",
        "# Rename encoded columns\n",
        "White_Wine_encode_df.columns = enc.get_feature_names(White_Wine_cat)\n",
        "White_Wine_encode_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation_Napa Valley</th>\n",
              "      <th>appellation_Other</th>\n",
              "      <th>wine_Alpha Omega, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Alpha Omega, Reserve Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Apsara Cellars, 'Rivers Reach' Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Araujo Estate, Eisele Vineyard Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Aubert Wines, Hudson Vineyard Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Aubert Wines, Larry Hyde &amp; Sons Vineyard Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Aubert Wines, Ritchie Vineyard Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Aubert Wines, Sugar Shack Estate Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Aubert Wines, Uv-Sl Vineyards Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Beaulieu Vineyard Bv, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Beringer Vineyards, 'Luminus' Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Beringer Vineyards, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Beringer Vineyards, Private Reserve Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cakebread Cellars, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cakebread Cellars, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Cakebread Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Chappellet, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Charles Krug Peter Mondavi Family, Sauvignon Blanc, White, St Helena</th>\n",
              "      <th>wine_Chateau Montelena, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cliff Lede Vineyards, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Clos Du Val, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Clos Du Val, Winemaker'S Signature Series Three Graces White Blend, White, Napa Valley</th>\n",
              "      <th>wine_Crossbarn By Paul Hobbs, Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Cuvaison, Ats Selection Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Cuvaison, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Delille Cellars, Chaleur Estate Blanc, White, Columbia Valley</th>\n",
              "      <th>wine_Delille Cellars, Doyenne Metier Blanc, White, Red Mountain</th>\n",
              "      <th>wine_Delille Cellars, Doyenne Roussanne, White, Red Mountain</th>\n",
              "      <th>wine_Domaine Serene, 'Dijon Clones - Cote Sud Vineyard' Chardonnay, White, Willamette Valley</th>\n",
              "      <th>wine_Domaine Serene, 'Evenstad Reserve' Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Domaine Serene, Clos Du Soleil Vineyard Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Domaine Serene, Etoile Vineyard Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Duckhorn Vineyards, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Duckhorn Vineyards, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Dumol, Clare Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Etude, Grace Benoist Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Etude, Pinot Gris, White, Carneros</th>\n",
              "      <th>wine_Evening Land, Gold Label Seven Springs Vineyard Chardonnay, White, Eola-Amity Hills</th>\n",
              "      <th>...</th>\n",
              "      <th>wine_Robert Foley Vineyards, Pinot Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Napa Valley Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Rombauer Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Rudd, Bacigalupi Vineyard Chardonnay, White, Russian River Valley</th>\n",
              "      <th>wine_Rudd, Mount Veeder Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Saintsbury, Brown Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Screaming Eagle, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Shafer Vineyards, Red Shoulder Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards Estate, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, 'Vineburg Vineyard' Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, Miller Ranch Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Smith Madrone, Riesling, White, Spring Mountain District</th>\n",
              "      <th>wine_Spottswoode, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_St. Clement Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Arcadia Vineyard Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Aveta Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Karia Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stags' Leap Winery, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Trefethen Family Vineyards, Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Truchard Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Truchard Vineyards, Roussanne, White, Carneros</th>\n",
              "      <th>wine_Turnbull Wine Cellars, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Twomey Cellars, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_Venge Vineyards, Maldonado Vineyard Dijon Clones Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Vine Cliff Winery, Chardonnay, White, Los Carneros</th>\n",
              "      <th>color_White</th>\n",
              "      <th>regions_California</th>\n",
              "      <th>regions_Oregon</th>\n",
              "      <th>regions_Washington</th>\n",
              "      <th>country_Usa</th>\n",
              "      <th>confidence_index_A</th>\n",
              "      <th>confidence_index_A+</th>\n",
              "      <th>confidence_index_B</th>\n",
              "      <th>confidence_index_B+</th>\n",
              "      <th>confidence_index_C</th>\n",
              "      <th>confidence_index_C+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 176 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   appellation_Napa Valley  ...  confidence_index_C+\n",
              "0                      0.0  ...                  0.0\n",
              "1                      1.0  ...                  1.0\n",
              "2                      0.0  ...                  0.0\n",
              "3                      0.0  ...                  0.0\n",
              "4                      1.0  ...                  0.0\n",
              "\n",
              "[5 rows x 176 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4QT7qzO5-N",
        "outputId": "734740fa-0051-4a41-ec85-5a841bada643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "White_Soil_ML_df = White_Soil_ML_df.merge(White_Wine_encode_df,left_index=True, right_index=True)\n",
        "White_Soil_ML_df = White_Soil_ML_df.drop(White_Wine_cat,1)\n",
        "White_Soil_ML_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>...</th>\n",
              "      <th>wine_Robert Foley Vineyards, Pinot Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Napa Valley Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Rombauer Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Rudd, Bacigalupi Vineyard Chardonnay, White, Russian River Valley</th>\n",
              "      <th>wine_Rudd, Mount Veeder Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Saintsbury, Brown Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Screaming Eagle, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Shafer Vineyards, Red Shoulder Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards Estate, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, 'Vineburg Vineyard' Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, Miller Ranch Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Smith Madrone, Riesling, White, Spring Mountain District</th>\n",
              "      <th>wine_Spottswoode, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_St. Clement Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Arcadia Vineyard Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Aveta Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Karia Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stags' Leap Winery, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Trefethen Family Vineyards, Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Truchard Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Truchard Vineyards, Roussanne, White, Carneros</th>\n",
              "      <th>wine_Turnbull Wine Cellars, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Twomey Cellars, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_Venge Vineyards, Maldonado Vineyard Dijon Clones Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Vine Cliff Winery, Chardonnay, White, Los Carneros</th>\n",
              "      <th>color_White</th>\n",
              "      <th>regions_California</th>\n",
              "      <th>regions_Oregon</th>\n",
              "      <th>regions_Washington</th>\n",
              "      <th>country_Usa</th>\n",
              "      <th>confidence_index_A</th>\n",
              "      <th>confidence_index_A+</th>\n",
              "      <th>confidence_index_B</th>\n",
              "      <th>confidence_index_B+</th>\n",
              "      <th>confidence_index_C</th>\n",
              "      <th>confidence_index_C+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>107658</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.5</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.7</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111897</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101640</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101640</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91591</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 221 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wine_id  vintage  ...  confidence_index_C  confidence_index_C+\n",
              "0   107658     2015  ...                 0.0                  0.0\n",
              "1   111897     2015  ...                 0.0                  1.0\n",
              "2   101640     1993  ...                 1.0                  0.0\n",
              "3   101640     1998  ...                 0.0                  0.0\n",
              "4    91591     2015  ...                 0.0                  0.0\n",
              "\n",
              "[5 rows x 221 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uPm_kDc8Fon"
      },
      "source": [
        "## ***Wine Only - Drop All weather and soil columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCbZATbmO5-Q"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\", \"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\", 'avgPrcpFebruary',\n",
        " 'avgTempFebruary',\n",
        " 'avgPrcpMarch',\n",
        " 'avgTempMarch',\n",
        " 'avgPrcpApril',\n",
        " 'avgTempApril',\n",
        " 'avgPrcpMay',\n",
        " 'avgTempMay',\n",
        " 'avgPrcpJune',\n",
        " 'avgTempJune',\n",
        " 'avgPrcpJuly',\n",
        " 'avgTempJuly',\n",
        " 'avgPrcpAugust',\n",
        " 'avgTempAugust',\n",
        " 'avgPrcpSeptember',\n",
        " 'avgTempSeptember',\n",
        " 'avgPrcpOctober',\n",
        " 'avgTempOctober',\n",
        " 'bdod_0-100cm',\n",
        " 'bdod_100-200cm',\n",
        " 'cec_0-100cm',\n",
        " 'cec_100-200cm',\n",
        " 'cfvo_0-100cm',\n",
        " 'cfvo_100-200cm',\n",
        " 'clay_0-100cm',\n",
        " 'clay_100-200cm',\n",
        " 'nitrogen_0-100cm',\n",
        " 'nitrogen_100-200cm',\n",
        " 'ocd_0-100cm',\n",
        " 'ocd_100-200cm',\n",
        " 'ocs_0-30cm',\n",
        " 'phh2o_0-100cm',\n",
        " 'phh2o_100-200cm',\n",
        " 'sand_0-100cm',\n",
        " 'sand_100-200cm',\n",
        " 'silt_0-100cm',\n",
        " 'silt_100-200cm',\n",
        " 'soc_0-100cm',\n",
        " 'soc_100-200cm'],1).values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE4Fr6BaJ-Ep"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=45)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcVEIlvIO5-S"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G73C39aiO5-V"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7Lvg2HO5-V",
        "outputId": "2a3f5cf4-2941-443c-a6b8-de2f206e0553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5,verbose=2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 - 0s - loss: 0.6743 - accuracy: 0.5693 - val_loss: 0.6884 - val_accuracy: 0.5855\n",
            "Epoch 2/50\n",
            "9/9 - 0s - loss: 0.5908 - accuracy: 0.6679 - val_loss: 0.6263 - val_accuracy: 0.6727\n",
            "Epoch 3/50\n",
            "9/9 - 0s - loss: 0.5369 - accuracy: 0.7190 - val_loss: 0.5829 - val_accuracy: 0.6873\n",
            "Epoch 4/50\n",
            "9/9 - 0s - loss: 0.4963 - accuracy: 0.8102 - val_loss: 0.5498 - val_accuracy: 0.7709\n",
            "Epoch 5/50\n",
            "9/9 - 0s - loss: 0.4612 - accuracy: 0.8467 - val_loss: 0.5215 - val_accuracy: 0.8073\n",
            "Epoch 6/50\n",
            "9/9 - 0s - loss: 0.4294 - accuracy: 0.8577 - val_loss: 0.5000 - val_accuracy: 0.8182\n",
            "Epoch 7/50\n",
            "9/9 - 0s - loss: 0.4013 - accuracy: 0.8759 - val_loss: 0.4793 - val_accuracy: 0.8145\n",
            "Epoch 8/50\n",
            "9/9 - 0s - loss: 0.3749 - accuracy: 0.8759 - val_loss: 0.4616 - val_accuracy: 0.8145\n",
            "Epoch 9/50\n",
            "9/9 - 0s - loss: 0.3524 - accuracy: 0.8759 - val_loss: 0.4435 - val_accuracy: 0.8182\n",
            "Epoch 10/50\n",
            "9/9 - 0s - loss: 0.3308 - accuracy: 0.8723 - val_loss: 0.4285 - val_accuracy: 0.8255\n",
            "Epoch 11/50\n",
            "9/9 - 0s - loss: 0.3116 - accuracy: 0.8796 - val_loss: 0.4148 - val_accuracy: 0.8364\n",
            "Epoch 12/50\n",
            "9/9 - 0s - loss: 0.2936 - accuracy: 0.8796 - val_loss: 0.4019 - val_accuracy: 0.8545\n",
            "Epoch 13/50\n",
            "9/9 - 0s - loss: 0.2772 - accuracy: 0.8796 - val_loss: 0.3906 - val_accuracy: 0.8545\n",
            "Epoch 14/50\n",
            "9/9 - 0s - loss: 0.2640 - accuracy: 0.8869 - val_loss: 0.3811 - val_accuracy: 0.8582\n",
            "Epoch 15/50\n",
            "9/9 - 0s - loss: 0.2504 - accuracy: 0.8905 - val_loss: 0.3710 - val_accuracy: 0.8691\n",
            "Epoch 16/50\n",
            "9/9 - 0s - loss: 0.2379 - accuracy: 0.8978 - val_loss: 0.3634 - val_accuracy: 0.8764\n",
            "Epoch 17/50\n",
            "9/9 - 0s - loss: 0.2278 - accuracy: 0.9051 - val_loss: 0.3567 - val_accuracy: 0.8691\n",
            "Epoch 18/50\n",
            "9/9 - 0s - loss: 0.2184 - accuracy: 0.9088 - val_loss: 0.3507 - val_accuracy: 0.8764\n",
            "Epoch 19/50\n",
            "9/9 - 0s - loss: 0.2098 - accuracy: 0.9088 - val_loss: 0.3449 - val_accuracy: 0.8836\n",
            "Epoch 20/50\n",
            "9/9 - 0s - loss: 0.2014 - accuracy: 0.9197 - val_loss: 0.3405 - val_accuracy: 0.8836\n",
            "Epoch 21/50\n",
            "9/9 - 0s - loss: 0.1937 - accuracy: 0.9234 - val_loss: 0.3373 - val_accuracy: 0.8873\n",
            "Epoch 22/50\n",
            "9/9 - 0s - loss: 0.1870 - accuracy: 0.9234 - val_loss: 0.3347 - val_accuracy: 0.8873\n",
            "Epoch 23/50\n",
            "9/9 - 0s - loss: 0.1803 - accuracy: 0.9270 - val_loss: 0.3309 - val_accuracy: 0.8909\n",
            "Epoch 24/50\n",
            "9/9 - 0s - loss: 0.1745 - accuracy: 0.9270 - val_loss: 0.3289 - val_accuracy: 0.8873\n",
            "Epoch 25/50\n",
            "9/9 - 0s - loss: 0.1674 - accuracy: 0.9307 - val_loss: 0.3260 - val_accuracy: 0.8909\n",
            "Epoch 26/50\n",
            "9/9 - 0s - loss: 0.1623 - accuracy: 0.9307 - val_loss: 0.3229 - val_accuracy: 0.8909\n",
            "Epoch 27/50\n",
            "9/9 - 0s - loss: 0.1565 - accuracy: 0.9307 - val_loss: 0.3207 - val_accuracy: 0.8909\n",
            "Epoch 28/50\n",
            "9/9 - 0s - loss: 0.1519 - accuracy: 0.9343 - val_loss: 0.3187 - val_accuracy: 0.8909\n",
            "Epoch 29/50\n",
            "9/9 - 0s - loss: 0.1453 - accuracy: 0.9380 - val_loss: 0.3179 - val_accuracy: 0.8873\n",
            "Epoch 30/50\n",
            "9/9 - 0s - loss: 0.1407 - accuracy: 0.9453 - val_loss: 0.3172 - val_accuracy: 0.8873\n",
            "Epoch 31/50\n",
            "9/9 - 0s - loss: 0.1350 - accuracy: 0.9562 - val_loss: 0.3172 - val_accuracy: 0.8873\n",
            "Epoch 32/50\n",
            "9/9 - 0s - loss: 0.1309 - accuracy: 0.9562 - val_loss: 0.3178 - val_accuracy: 0.8764\n",
            "Epoch 33/50\n",
            "9/9 - 0s - loss: 0.1260 - accuracy: 0.9562 - val_loss: 0.3156 - val_accuracy: 0.8800\n",
            "Epoch 34/50\n",
            "9/9 - 0s - loss: 0.1226 - accuracy: 0.9635 - val_loss: 0.3158 - val_accuracy: 0.8836\n",
            "Epoch 35/50\n",
            "9/9 - 0s - loss: 0.1184 - accuracy: 0.9562 - val_loss: 0.3122 - val_accuracy: 0.8836\n",
            "Epoch 36/50\n",
            "9/9 - 0s - loss: 0.1137 - accuracy: 0.9672 - val_loss: 0.3121 - val_accuracy: 0.8800\n",
            "Epoch 37/50\n",
            "9/9 - 0s - loss: 0.1106 - accuracy: 0.9635 - val_loss: 0.3119 - val_accuracy: 0.8800\n",
            "Epoch 38/50\n",
            "9/9 - 0s - loss: 0.1075 - accuracy: 0.9672 - val_loss: 0.3118 - val_accuracy: 0.8764\n",
            "Epoch 39/50\n",
            "9/9 - 0s - loss: 0.1042 - accuracy: 0.9672 - val_loss: 0.3112 - val_accuracy: 0.8800\n",
            "Epoch 40/50\n",
            "9/9 - 0s - loss: 0.1007 - accuracy: 0.9708 - val_loss: 0.3104 - val_accuracy: 0.8764\n",
            "Epoch 41/50\n",
            "9/9 - 0s - loss: 0.0988 - accuracy: 0.9708 - val_loss: 0.3100 - val_accuracy: 0.8800\n",
            "Epoch 42/50\n",
            "9/9 - 0s - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.3078 - val_accuracy: 0.8764\n",
            "Epoch 43/50\n",
            "9/9 - 0s - loss: 0.0918 - accuracy: 0.9708 - val_loss: 0.3090 - val_accuracy: 0.8727\n",
            "Epoch 44/50\n",
            "9/9 - 0s - loss: 0.0888 - accuracy: 0.9781 - val_loss: 0.3074 - val_accuracy: 0.8764\n",
            "Epoch 45/50\n",
            "9/9 - 0s - loss: 0.0875 - accuracy: 0.9708 - val_loss: 0.3096 - val_accuracy: 0.8764\n",
            "Epoch 46/50\n",
            "9/9 - 0s - loss: 0.0847 - accuracy: 0.9708 - val_loss: 0.3116 - val_accuracy: 0.8727\n",
            "Epoch 47/50\n",
            "9/9 - 0s - loss: 0.0824 - accuracy: 0.9818 - val_loss: 0.3123 - val_accuracy: 0.8764\n",
            "Epoch 48/50\n",
            "9/9 - 0s - loss: 0.0804 - accuracy: 0.9781 - val_loss: 0.3122 - val_accuracy: 0.8691\n",
            "Epoch 49/50\n",
            "9/9 - 0s - loss: 0.0781 - accuracy: 0.9781 - val_loss: 0.3128 - val_accuracy: 0.8727\n",
            "Epoch 50/50\n",
            "9/9 - 0s - loss: 0.0761 - accuracy: 0.9818 - val_loss: 0.3125 - val_accuracy: 0.8764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYkzjY0Jpn4",
        "outputId": "528d71d3-3a22-48fb-dca3-d537909a8345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw6xMQP-O5-X"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-6Z3XUQsali",
        "outputId": "6c00c7c9-c7f0-4d21-e6f2-b55735cf7930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.8251\n",
            "Loss: 0.617729663848877, Accuracy: 0.8251366019248962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uQLqejXO5-Z"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdKZ89DiBfB",
        "outputId": "4556d83e-b7a7-4f7d-caeb-bf2b96200c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.004413630813360214,\n",
              " 0.01945793628692627,\n",
              " 76.45147442817688,\n",
              " 0.0035897042835131288,\n",
              " 0.0786125659942627,\n",
              " 99.93321895599365,\n",
              " 89.23664689064026,\n",
              " 97.30216264724731,\n",
              " 44.21732425689697,\n",
              " 4.809907078742981,\n",
              " 0.004182724660495296,\n",
              " 1.1397302150726318,\n",
              " 99.09971952438354,\n",
              " 35.24186313152313,\n",
              " 1.7711281776428223,\n",
              " 0.04685819149017334,\n",
              " 94.7239875793457,\n",
              " 98.95755648612976,\n",
              " 1.0676771402359009,\n",
              " 99.10102486610413,\n",
              " 53.88973355293274,\n",
              " 96.44925594329834,\n",
              " 2.4216562509536743,\n",
              " 0.3737032413482666,\n",
              " 94.09182667732239,\n",
              " 80.8912992477417,\n",
              " 99.95784759521484,\n",
              " 76.79928541183472,\n",
              " 76.44063234329224,\n",
              " 0.0041166840674122795,\n",
              " 7.866436817494105e-05,\n",
              " 99.9476432800293,\n",
              " 0.019100308418273926,\n",
              " 26.32613778114319,\n",
              " 86.05205416679382,\n",
              " 0.11294186115264893,\n",
              " 99.88076686859131,\n",
              " 99.66808557510376,\n",
              " 99.99309778213501,\n",
              " 0.013256072998046875,\n",
              " 96.8280553817749,\n",
              " 0.10027587413787842,\n",
              " 95.95495462417603,\n",
              " 99.11651015281677,\n",
              " 0.9011030197143555,\n",
              " 99.9276876449585,\n",
              " 1.0956048965454102,\n",
              " 42.69261360168457,\n",
              " 89.38390016555786,\n",
              " 99.93342161178589,\n",
              " 2.514272928237915,\n",
              " 96.21089696884155,\n",
              " 99.85026121139526,\n",
              " 6.0614705085754395,\n",
              " 99.79420900344849,\n",
              " 0.27385056018829346,\n",
              " 98.44061732292175,\n",
              " 3.3452272415161133,\n",
              " 99.97797012329102,\n",
              " 99.67604875564575,\n",
              " 92.96867847442627,\n",
              " 19.7679340839386,\n",
              " 97.02847003936768,\n",
              " 0.018972158432006836,\n",
              " 97.8597640991211,\n",
              " 84.19358134269714,\n",
              " 53.98740768432617,\n",
              " 98.02132844924927,\n",
              " 99.98155236244202,\n",
              " 4.9649059772491455,\n",
              " 87.1137261390686,\n",
              " 99.77840185165405,\n",
              " 29.870998859405518,\n",
              " 83.55885744094849,\n",
              " 11.231014132499695,\n",
              " 94.39062476158142,\n",
              " 0.0035587538150139153,\n",
              " 96.42738103866577,\n",
              " 94.47879791259766,\n",
              " 98.81683588027954,\n",
              " 5.660355091094971,\n",
              " 0.041106343269348145,\n",
              " 0.04876554012298584,\n",
              " 99.56322908401489,\n",
              " 99.79124069213867,\n",
              " 0.0013778779248241335,\n",
              " 0.006046933776815422,\n",
              " 89.15453553199768,\n",
              " 0.07106363773345947,\n",
              " 97.5637674331665,\n",
              " 99.23533201217651,\n",
              " 0.17758309841156006,\n",
              " 0.000150698542711325,\n",
              " 98.69123697280884,\n",
              " 14.122959971427917,\n",
              " 93.7302827835083,\n",
              " 99.58829283714294,\n",
              " 0.01622140407562256,\n",
              " 99.84256625175476,\n",
              " 99.94615316390991,\n",
              " 0.0009928761755872983,\n",
              " 99.80932474136353,\n",
              " 94.99990940093994,\n",
              " 62.47174143791199,\n",
              " 99.90707635879517,\n",
              " 84.05374884605408,\n",
              " 97.95842170715332,\n",
              " 16.892698407173157,\n",
              " 94.4401741027832,\n",
              " 31.15515112876892,\n",
              " 7.660067081451416,\n",
              " 0.013425946235656738,\n",
              " 96.1794912815094,\n",
              " 0.9652316570281982,\n",
              " 99.9782145023346,\n",
              " 1.6201049089431763,\n",
              " 1.7258644104003906,\n",
              " 99.11147356033325,\n",
              " 0.0003942780040233629,\n",
              " 0.9994924068450928,\n",
              " 1.6461580991744995,\n",
              " 66.34824275970459,\n",
              " 20.82253396511078,\n",
              " 0.7130682468414307,\n",
              " 99.91048574447632,\n",
              " 0.0552445650100708,\n",
              " 19.39130425453186,\n",
              " 0.02778768539428711,\n",
              " 0.0062667801103089005,\n",
              " 98.67151379585266,\n",
              " 96.74010276794434,\n",
              " 99.63171482086182,\n",
              " 99.93359446525574,\n",
              " 0.06532669067382812,\n",
              " 99.7239351272583,\n",
              " 69.80147957801819,\n",
              " 92.28562116622925,\n",
              " 0.0077495104051195085,\n",
              " 42.720115184783936,\n",
              " 0.002478217902535107,\n",
              " 65.4511034488678,\n",
              " 99.40259456634521,\n",
              " 92.68302321434021,\n",
              " 0.0037590514693874866,\n",
              " 16.994675993919373,\n",
              " 99.31201934814453,\n",
              " 99.3881106376648,\n",
              " 44.70351040363312,\n",
              " 91.92232489585876,\n",
              " 0.037661194801330566,\n",
              " 96.16937041282654,\n",
              " 0.861203670501709,\n",
              " 0.007362153701251373,\n",
              " 2.719736099243164,\n",
              " 0.0006166684215713758,\n",
              " 91.7051911354065,\n",
              " 84.14332866668701,\n",
              " 0.003247605127398856,\n",
              " 0.03546178340911865,\n",
              " 97.82460927963257,\n",
              " 0.2382427453994751,\n",
              " 52.16872692108154,\n",
              " 86.17099523544312,\n",
              " 18.79664957523346,\n",
              " 99.81765747070312,\n",
              " 99.45805668830872,\n",
              " 21.771931648254395,\n",
              " 40.61748683452606,\n",
              " 87.19565868377686,\n",
              " 2.027308940887451,\n",
              " 81.64871335029602,\n",
              " 2.662530541419983,\n",
              " 99.27058219909668,\n",
              " 0.001947564487636555,\n",
              " 1.3695716857910156,\n",
              " 0.0398099422454834,\n",
              " 0.29934942722320557,\n",
              " 99.77079629898071,\n",
              " 67.22482442855835,\n",
              " 0.450095534324646,\n",
              " 99.92822408676147,\n",
              " 93.13114285469055,\n",
              " 0.0009699039765109774]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_6G4L1TO5-d"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stnp4Ep3O5-d",
        "outputId": "88000000-7ef4-42e7-ee55-c507e9686bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_pG1RM0JDwr",
        "outputId": "39c3a05d-edc4-4bb8-e5b4-7fc661dc1750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 75   0]\n",
            " [  0 108]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkIB9d0lslob"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baU-hliossZ1"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAiKwCp4suyg",
        "outputId": "7ebed72f-b597-4074-aac0-e190bf1f2148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiOZe0KQtHm1",
        "outputId": "cf4b7077-1213-4d0b-fc4d-9c9226501671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUKD1EJUtLhy",
        "outputId": "fa5c603d-08c3-4e09-ece7-bc32c776ecab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp_KzZnUJQg_",
        "outputId": "e84bdb99-a9c1-4563-c83d-6cd2d8e4e8c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QIUMu-a8ZDw"
      },
      "source": [
        "## ***Wine & Weather - Drop All soil columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl3c8lXV8ZDx"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\", \"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\",'avgPrcpFebruary',\n",
        " 'bdod_0-100cm',\n",
        " 'bdod_100-200cm',\n",
        " 'cec_0-100cm',\n",
        " 'cec_100-200cm',\n",
        " 'cfvo_0-100cm',\n",
        " 'cfvo_100-200cm',\n",
        " 'clay_0-100cm',\n",
        " 'clay_100-200cm',\n",
        " 'nitrogen_0-100cm',\n",
        " 'nitrogen_100-200cm',\n",
        " 'ocd_0-100cm',\n",
        " 'ocd_100-200cm',\n",
        " 'ocs_0-30cm',\n",
        " 'phh2o_0-100cm',\n",
        " 'phh2o_100-200cm',\n",
        " 'sand_0-100cm',\n",
        " 'sand_100-200cm',\n",
        " 'silt_0-100cm',\n",
        " 'silt_100-200cm',\n",
        " 'soc_0-100cm',\n",
        " 'soc_100-200cm',],1).values"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf1KlblGsiak"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=45)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgW_GLNG8ZD1"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDkDyjKx8ZD4"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbMo7m578ZD4",
        "outputId": "2c93aff1-c668-455a-d20d-b87739ce916c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.7176 - accuracy: 0.4927 - val_loss: 0.6895 - val_accuracy: 0.5673\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.5876 - val_loss: 0.6574 - val_accuracy: 0.6109\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6569 - val_loss: 0.6311 - val_accuracy: 0.6582\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7153 - val_loss: 0.6064 - val_accuracy: 0.6800\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7555 - val_loss: 0.5833 - val_accuracy: 0.6982\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7920 - val_loss: 0.5597 - val_accuracy: 0.7164\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.8248 - val_loss: 0.5348 - val_accuracy: 0.7455\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8504 - val_loss: 0.5129 - val_accuracy: 0.7673\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8650 - val_loss: 0.4917 - val_accuracy: 0.7855\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8832 - val_loss: 0.4701 - val_accuracy: 0.8000\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8869 - val_loss: 0.4552 - val_accuracy: 0.7964\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8978 - val_loss: 0.4381 - val_accuracy: 0.8036\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.9051 - val_loss: 0.4268 - val_accuracy: 0.8109\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2805 - accuracy: 0.9124 - val_loss: 0.4115 - val_accuracy: 0.8145\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2598 - accuracy: 0.9161 - val_loss: 0.3957 - val_accuracy: 0.8218\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2419 - accuracy: 0.9161 - val_loss: 0.3859 - val_accuracy: 0.8255\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9197 - val_loss: 0.3792 - val_accuracy: 0.8327\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9161 - val_loss: 0.3749 - val_accuracy: 0.8327\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9161 - val_loss: 0.3647 - val_accuracy: 0.8364\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1836 - accuracy: 0.9270 - val_loss: 0.3583 - val_accuracy: 0.8436\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1722 - accuracy: 0.9343 - val_loss: 0.3519 - val_accuracy: 0.8473\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.9526 - val_loss: 0.3485 - val_accuracy: 0.8545\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9635 - val_loss: 0.3528 - val_accuracy: 0.8618\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9635 - val_loss: 0.3466 - val_accuracy: 0.8655\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.9672 - val_loss: 0.3402 - val_accuracy: 0.8655\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9708 - val_loss: 0.3458 - val_accuracy: 0.8655\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9745 - val_loss: 0.3409 - val_accuracy: 0.8655\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9745 - val_loss: 0.3360 - val_accuracy: 0.8727\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9745 - val_loss: 0.3351 - val_accuracy: 0.8727\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9781 - val_loss: 0.3340 - val_accuracy: 0.8727\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9818 - val_loss: 0.3435 - val_accuracy: 0.8727\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9854 - val_loss: 0.3407 - val_accuracy: 0.8727\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9818 - val_loss: 0.3355 - val_accuracy: 0.8691\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9854 - val_loss: 0.3402 - val_accuracy: 0.8727\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9854 - val_loss: 0.3416 - val_accuracy: 0.8727\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9854 - val_loss: 0.3432 - val_accuracy: 0.8764\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9891 - val_loss: 0.3348 - val_accuracy: 0.8764\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9854 - val_loss: 0.3402 - val_accuracy: 0.8764\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9891 - val_loss: 0.3433 - val_accuracy: 0.8727\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9891 - val_loss: 0.3514 - val_accuracy: 0.8727\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9891 - val_loss: 0.3484 - val_accuracy: 0.8764\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9927 - val_loss: 0.3439 - val_accuracy: 0.8764\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9927 - val_loss: 0.3489 - val_accuracy: 0.8764\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9964 - val_loss: 0.3540 - val_accuracy: 0.8764\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9964 - val_loss: 0.3475 - val_accuracy: 0.8764\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9964 - val_loss: 0.3557 - val_accuracy: 0.8764\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9964 - val_loss: 0.3601 - val_accuracy: 0.8764\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9891 - val_loss: 0.3517 - val_accuracy: 0.8764\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9927 - val_loss: 0.3659 - val_accuracy: 0.8764\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9927 - val_loss: 0.3668 - val_accuracy: 0.8764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyzl5ZaMB8L",
        "outputId": "06162431-19de-454b-ceb5-dfffc60126fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEcRZGXM8ZD8"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2_bXNR4tFKY",
        "outputId": "2005ac3d-292b-4adb-9c24-d37e1a497002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.5308 - accuracy: 0.8361\n",
            "Loss: 0.530778169631958, Accuracy: 0.8360655903816223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRFv96XA8ZD8"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJMznkl8ZEB",
        "outputId": "25b627ff-7b7f-481b-aa9e-0033b23a2083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05536377429962158,\n",
              " 0.051465630531311035,\n",
              " 91.83385372161865,\n",
              " 0.0483095645904541,\n",
              " 0.00013554470115195727,\n",
              " 99.92955923080444,\n",
              " 97.57356643676758,\n",
              " 42.2957181930542,\n",
              " 80.23739457130432,\n",
              " 3.0920416116714478,\n",
              " 0.0007143518359953305,\n",
              " 16.242793202400208,\n",
              " 92.5910234451294,\n",
              " 35.19834876060486,\n",
              " 3.7714719772338867,\n",
              " 0.014409422874450684,\n",
              " 90.13720750808716,\n",
              " 94.79790329933167,\n",
              " 0.8050858974456787,\n",
              " 93.61420273780823,\n",
              " 39.1947478055954,\n",
              " 97.53479361534119,\n",
              " 85.14552712440491,\n",
              " 3.106045722961426,\n",
              " 99.5124340057373,\n",
              " 78.00960540771484,\n",
              " 99.93479251861572,\n",
              " 96.3191270828247,\n",
              " 96.93629741668701,\n",
              " 0.004264172457624227,\n",
              " 0.21743178367614746,\n",
              " 99.98812675476074,\n",
              " 0.08515119552612305,\n",
              " 3.1916677951812744,\n",
              " 80.17418384552002,\n",
              " 0.026020407676696777,\n",
              " 99.92861747741699,\n",
              " 99.99826550483704,\n",
              " 99.59293603897095,\n",
              " 0.014650821685791016,\n",
              " 81.05899691581726,\n",
              " 0.026032328605651855,\n",
              " 6.246504187583923,\n",
              " 99.78901147842407,\n",
              " 0.7518202066421509,\n",
              " 99.93136525154114,\n",
              " 1.1802732944488525,\n",
              " 26.5458345413208,\n",
              " 72.12715148925781,\n",
              " 99.99123811721802,\n",
              " 1.9927680492401123,\n",
              " 99.36648607254028,\n",
              " 99.96113777160645,\n",
              " 4.573225975036621,\n",
              " 99.68373775482178,\n",
              " 2.55376398563385,\n",
              " 99.73553419113159,\n",
              " 0.5587339401245117,\n",
              " 99.98571872711182,\n",
              " 99.89627003669739,\n",
              " 98.8604187965393,\n",
              " 7.741174101829529,\n",
              " 99.58364367485046,\n",
              " 0.20398199558258057,\n",
              " 95.75741291046143,\n",
              " 85.6482744216919,\n",
              " 36.82236969470978,\n",
              " 98.55598211288452,\n",
              " 99.81217980384827,\n",
              " 81.34081959724426,\n",
              " 66.20672345161438,\n",
              " 99.99935626983643,\n",
              " 16.52299165725708,\n",
              " 99.53230619430542,\n",
              " 1.422169804573059,\n",
              " 96.44418954849243,\n",
              " 0.09233057498931885,\n",
              " 99.57627058029175,\n",
              " 95.6689715385437,\n",
              " 99.61351752281189,\n",
              " 13.627815246582031,\n",
              " 0.00017085798162952415,\n",
              " 0.09831786155700684,\n",
              " 99.77785348892212,\n",
              " 99.9753475189209,\n",
              " 1.3215810060501099,\n",
              " 0.04366934299468994,\n",
              " 69.1235363483429,\n",
              " 0.14406144618988037,\n",
              " 99.58943128585815,\n",
              " 99.57927465438843,\n",
              " 0.028401613235473633,\n",
              " 1.6016332438084646e-05,\n",
              " 99.7465968132019,\n",
              " 0.023245811462402344,\n",
              " 96.38907313346863,\n",
              " 99.918532371521,\n",
              " 0.1178741455078125,\n",
              " 99.91012215614319,\n",
              " 97.84526824951172,\n",
              " 0.005379465073929168,\n",
              " 99.98164176940918,\n",
              " 96.98092937469482,\n",
              " 60.80731153488159,\n",
              " 99.99099969863892,\n",
              " 87.15677857398987,\n",
              " 88.68019580841064,\n",
              " 7.757115364074707,\n",
              " 96.96850776672363,\n",
              " 29.72765564918518,\n",
              " 22.98734486103058,\n",
              " 0.003229749563615769,\n",
              " 99.82280731201172,\n",
              " 1.2749552726745605,\n",
              " 97.79510498046875,\n",
              " 1.6575902700424194,\n",
              " 2.702459692955017,\n",
              " 91.56382083892822,\n",
              " 0.01665949821472168,\n",
              " 10.829553008079529,\n",
              " 6.714266538619995,\n",
              " 66.69794917106628,\n",
              " 76.61627531051636,\n",
              " 8.612018823623657,\n",
              " 99.97227787971497,\n",
              " 0.006311498873401433,\n",
              " 16.531190276145935,\n",
              " 0.0002645578433657647,\n",
              " 1.30443274974823,\n",
              " 93.81521940231323,\n",
              " 99.6816635131836,\n",
              " 99.71123933792114,\n",
              " 99.96611475944519,\n",
              " 0.0003567873136489652,\n",
              " 99.94443655014038,\n",
              " 79.06277775764465,\n",
              " 99.99463558197021,\n",
              " 0.024890899658203125,\n",
              " 82.6653242111206,\n",
              " 0.0009536820471112151,\n",
              " 94.96099948883057,\n",
              " 99.10241365432739,\n",
              " 99.98888373374939,\n",
              " 0.21022558212280273,\n",
              " 15.703681111335754,\n",
              " 99.93000626564026,\n",
              " 97.21105098724365,\n",
              " 88.52179050445557,\n",
              " 98.56223464012146,\n",
              " 0.0682830810546875,\n",
              " 99.36821460723877,\n",
              " 0.31420886516571045,\n",
              " 0.004738350980915129,\n",
              " 1.4608323574066162,\n",
              " 0.01615285873413086,\n",
              " 91.45351648330688,\n",
              " 90.36749601364136,\n",
              " 0.025194883346557617,\n",
              " 0.3379553556442261,\n",
              " 99.63578581809998,\n",
              " 0.9734690189361572,\n",
              " 31.507447361946106,\n",
              " 95.23110389709473,\n",
              " 6.895449757575989,\n",
              " 99.82906579971313,\n",
              " 97.82995581626892,\n",
              " 11.866053938865662,\n",
              " 17.9419606924057,\n",
              " 17.604708671569824,\n",
              " 0.2532660961151123,\n",
              " 89.84544277191162,\n",
              " 1.649916172027588,\n",
              " 99.73433017730713,\n",
              " 0.03070533275604248,\n",
              " 14.102321863174438,\n",
              " 0.07357299327850342,\n",
              " 0.7785230875015259,\n",
              " 99.82202649116516,\n",
              " 95.66202759742737,\n",
              " 1.9749730825424194,\n",
              " 99.92519617080688,\n",
              " 98.59259128570557,\n",
              " 0.023749470710754395]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B21n32Y_8ZEI"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbi4Nt6S8ZEI",
        "outputId": "f0911c21-6622-46c3-daea-6f82c368ff32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ICcqS8oLBMd",
        "outputId": "9243b0fe-2de2-44a8-f6b4-eb2559f0509e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  5 103]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NPfSMqy8ZEO"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkpcmGoI8ZEP"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5RRLdU8ZEQ",
        "outputId": "f5e13d06-98e0-4c40-c32a-934e645367d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrQHR2e8ZER",
        "outputId": "cebdd3be-70d4-48b2-d29f-0dc8e1c6b192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXcYvmte8ZET",
        "outputId": "4e400365-11d4-43fd-ef04-c48a0e73e18c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9016393442622951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IgWEnV9LFQH",
        "outputId": "fb38c7f9-ede4-44a4-f8f6-160428b61abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[67  8]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnWP0hsq8zrQ"
      },
      "source": [
        "## ***Wine & Soil - Drop All weather columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zjTIfIy8zrR"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\",\"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\",'avgPrcpFebruary',\n",
        " 'avgTempFebruary',\n",
        " 'avgPrcpMarch',\n",
        " 'avgTempMarch',\n",
        " 'avgPrcpApril',\n",
        " 'avgTempApril',\n",
        " 'avgPrcpMay',\n",
        " 'avgTempMay',\n",
        " 'avgPrcpJune',\n",
        " 'avgTempJune',\n",
        " 'avgPrcpJuly',\n",
        " 'avgTempJuly',\n",
        " 'avgPrcpAugust',\n",
        " 'avgTempAugust',\n",
        " 'avgPrcpSeptember',\n",
        " 'avgTempSeptember',\n",
        " 'avgPrcpOctober',\n",
        " 'avgTempOctober'],1).values"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYmUXKWIuKQK"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=45)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvoFDc1r8zrV"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLZR5S938zrY"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GH0R3gB8zrZ",
        "outputId": "7e3557fd-659c-454b-edcd-49eb9e9aed76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.9023 - accuracy: 0.4526 - val_loss: 0.8249 - val_accuracy: 0.5273\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7511 - accuracy: 0.5365 - val_loss: 0.7377 - val_accuracy: 0.6036\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.6387 - val_loss: 0.6785 - val_accuracy: 0.6509\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7117 - val_loss: 0.6361 - val_accuracy: 0.7164\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7810 - val_loss: 0.6020 - val_accuracy: 0.7455\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.8029 - val_loss: 0.5749 - val_accuracy: 0.7782\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.8321 - val_loss: 0.5479 - val_accuracy: 0.7782\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8358 - val_loss: 0.5265 - val_accuracy: 0.7782\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8577 - val_loss: 0.5105 - val_accuracy: 0.7745\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8759 - val_loss: 0.4951 - val_accuracy: 0.7782\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8869 - val_loss: 0.4753 - val_accuracy: 0.7855\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8869 - val_loss: 0.4580 - val_accuracy: 0.7927\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8869 - val_loss: 0.4426 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2933 - accuracy: 0.9051 - val_loss: 0.4319 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.9161 - val_loss: 0.4213 - val_accuracy: 0.8073\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9197 - val_loss: 0.4087 - val_accuracy: 0.8182\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.9124 - val_loss: 0.3995 - val_accuracy: 0.8255\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2343 - accuracy: 0.9197 - val_loss: 0.3909 - val_accuracy: 0.8291\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9234 - val_loss: 0.3868 - val_accuracy: 0.8291\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9307 - val_loss: 0.3783 - val_accuracy: 0.8255\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2022 - accuracy: 0.9343 - val_loss: 0.3704 - val_accuracy: 0.8255\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9380 - val_loss: 0.3662 - val_accuracy: 0.8255\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9307 - val_loss: 0.3616 - val_accuracy: 0.8291\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9307 - val_loss: 0.3601 - val_accuracy: 0.8327\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9307 - val_loss: 0.3563 - val_accuracy: 0.8327\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1630 - accuracy: 0.9343 - val_loss: 0.3533 - val_accuracy: 0.8364\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9343 - val_loss: 0.3485 - val_accuracy: 0.8364\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9416 - val_loss: 0.3470 - val_accuracy: 0.8364\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1451 - accuracy: 0.9380 - val_loss: 0.3484 - val_accuracy: 0.8364\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.9453 - val_loss: 0.3469 - val_accuracy: 0.8436\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1348 - accuracy: 0.9380 - val_loss: 0.3462 - val_accuracy: 0.8436\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9489 - val_loss: 0.3420 - val_accuracy: 0.8436\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9489 - val_loss: 0.3381 - val_accuracy: 0.8436\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9526 - val_loss: 0.3390 - val_accuracy: 0.8400\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9562 - val_loss: 0.3389 - val_accuracy: 0.8509\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9599 - val_loss: 0.3391 - val_accuracy: 0.8436\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1088 - accuracy: 0.9672 - val_loss: 0.3409 - val_accuracy: 0.8436\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9672 - val_loss: 0.3383 - val_accuracy: 0.8473\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 0.9635 - val_loss: 0.3339 - val_accuracy: 0.8436\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9599 - val_loss: 0.3337 - val_accuracy: 0.8509\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9635 - val_loss: 0.3419 - val_accuracy: 0.8436\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9672 - val_loss: 0.3374 - val_accuracy: 0.8509\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9599 - val_loss: 0.3363 - val_accuracy: 0.8545\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9599 - val_loss: 0.3410 - val_accuracy: 0.8545\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9781 - val_loss: 0.3344 - val_accuracy: 0.8582\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9745 - val_loss: 0.3338 - val_accuracy: 0.8582\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9672 - val_loss: 0.3372 - val_accuracy: 0.8582\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9708 - val_loss: 0.3353 - val_accuracy: 0.8618\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9818 - val_loss: 0.3261 - val_accuracy: 0.8691\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9745 - val_loss: 0.3289 - val_accuracy: 0.8691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ag1d7XoMJF9",
        "outputId": "589ecb5a-13a1-48f0-89d9-c8e00a1f0d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-Cju5lo8zrb"
      },
      "source": [
        "###***Deep Learning Neural Network Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZlaGKpUtLqL",
        "outputId": "04f3b856-279d-4aa5-c902-258bfcd5f44b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.5466 - accuracy: 0.8306\n",
            "Loss: 0.5466492176055908, Accuracy: 0.8306010961532593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NTSC0Kk8zrc"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFA_Xo9k8zrg",
        "outputId": "cf393106-7c30-4659-965d-0be679274ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04883706569671631,\n",
              " 0.30621886253356934,\n",
              " 64.85518217086792,\n",
              " 0.10418891906738281,\n",
              " 0.26322007179260254,\n",
              " 99.99793767929077,\n",
              " 94.40741539001465,\n",
              " 71.53105735778809,\n",
              " 44.78049874305725,\n",
              " 5.033311247825623,\n",
              " 0.011589928908506408,\n",
              " 4.728120565414429,\n",
              " 98.81714582443237,\n",
              " 28.621754050254822,\n",
              " 8.469200134277344,\n",
              " 0.08969604969024658,\n",
              " 79.486745595932,\n",
              " 97.37212657928467,\n",
              " 1.7746657133102417,\n",
              " 99.11419153213501,\n",
              " 41.68235659599304,\n",
              " 97.47642874717712,\n",
              " 95.4993724822998,\n",
              " 1.548326015472412,\n",
              " 91.40721559524536,\n",
              " 32.85319805145264,\n",
              " 99.8762845993042,\n",
              " 72.68850207328796,\n",
              " 91.99000597000122,\n",
              " 0.0004596854978444753,\n",
              " 0.21219253540039062,\n",
              " 99.99275803565979,\n",
              " 0.6644010543823242,\n",
              " 27.944988012313843,\n",
              " 36.67391538619995,\n",
              " 0.1150280237197876,\n",
              " 99.8819351196289,\n",
              " 94.73617672920227,\n",
              " 99.86691474914551,\n",
              " 0.0019009330571861938,\n",
              " 65.52891135215759,\n",
              " 0.13458430767059326,\n",
              " 49.039289355278015,\n",
              " 83.67440700531006,\n",
              " 1.5321433544158936,\n",
              " 99.87928867340088,\n",
              " 4.067721962928772,\n",
              " 31.15208148956299,\n",
              " 44.08594071865082,\n",
              " 99.44214820861816,\n",
              " 3.164440393447876,\n",
              " 93.75773668289185,\n",
              " 99.09471273422241,\n",
              " 5.968531966209412,\n",
              " 99.68253374099731,\n",
              " 0.9995907545089722,\n",
              " 97.80206084251404,\n",
              " 0.45000314712524414,\n",
              " 99.92371797561646,\n",
              " 98.66886734962463,\n",
              " 92.91596412658691,\n",
              " 0.5113154649734497,\n",
              " 97.87232875823975,\n",
              " 0.3920435905456543,\n",
              " 81.54168128967285,\n",
              " 7.252880930900574,\n",
              " 40.24842083454132,\n",
              " 98.97651672363281,\n",
              " 99.70685243606567,\n",
              " 97.31394052505493,\n",
              " 45.969006419181824,\n",
              " 94.88980770111084,\n",
              " 12.700140476226807,\n",
              " 99.90971088409424,\n",
              " 0.1126021146774292,\n",
              " 96.11281156539917,\n",
              " 0.1460641622543335,\n",
              " 97.29379415512085,\n",
              " 88.57019543647766,\n",
              " 99.10963773727417,\n",
              " 7.637777924537659,\n",
              " 0.04305541515350342,\n",
              " 0.10579526424407959,\n",
              " 99.83557462692261,\n",
              " 99.01725053787231,\n",
              " 0.013306736946105957,\n",
              " 0.5231142044067383,\n",
              " 61.52629256248474,\n",
              " 0.2550184726715088,\n",
              " 99.9573826789856,\n",
              " 99.72172975540161,\n",
              " 0.03967583179473877,\n",
              " 0.008200616139220074,\n",
              " 98.14625978469849,\n",
              " 3.369256854057312,\n",
              " 90.98241329193115,\n",
              " 99.08384084701538,\n",
              " 0.3445476293563843,\n",
              " 99.61342811584473,\n",
              " 99.19207096099854,\n",
              " 0.16389787197113037,\n",
              " 99.48325157165527,\n",
              " 95.82662582397461,\n",
              " 65.04712104797363,\n",
              " 99.39063787460327,\n",
              " 77.45938301086426,\n",
              " 93.57367753982544,\n",
              " 10.396447777748108,\n",
              " 96.07080221176147,\n",
              " 10.0810706615448,\n",
              " 15.194785594940186,\n",
              " 1.766139268875122,\n",
              " 98.63669872283936,\n",
              " 0.6631463766098022,\n",
              " 99.67695474624634,\n",
              " 1.094961166381836,\n",
              " 17.137673497200012,\n",
              " 99.02464151382446,\n",
              " 0.009620033233659342,\n",
              " 3.096216917037964,\n",
              " 2.991989254951477,\n",
              " 86.32628917694092,\n",
              " 5.482432246208191,\n",
              " 3.5793691873550415,\n",
              " 99.69683885574341,\n",
              " 1.7061680555343628,\n",
              " 17.96538531780243,\n",
              " 0.047516822814941406,\n",
              " 0.7509350776672363,\n",
              " 96.4550256729126,\n",
              " 97.95105457305908,\n",
              " 99.30806159973145,\n",
              " 99.99008178710938,\n",
              " 0.08075237274169922,\n",
              " 99.46452975273132,\n",
              " 53.70818376541138,\n",
              " 99.96833205223083,\n",
              " 0.04658102989196777,\n",
              " 44.444113969802856,\n",
              " 0.0002975008783323574,\n",
              " 86.25401854515076,\n",
              " 99.17935729026794,\n",
              " 99.97204542160034,\n",
              " 0.03038346767425537,\n",
              " 17.95545518398285,\n",
              " 98.2672929763794,\n",
              " 99.51486587524414,\n",
              " 50.41041970252991,\n",
              " 93.00386309623718,\n",
              " 0.37833452224731445,\n",
              " 96.22112512588501,\n",
              " 4.715237021446228,\n",
              " 0.007336991257034242,\n",
              " 1.5200287103652954,\n",
              " 0.015404820442199707,\n",
              " 36.85457408428192,\n",
              " 12.745493650436401,\n",
              " 0.4073143005371094,\n",
              " 0.7785975933074951,\n",
              " 97.36921191215515,\n",
              " 1.2328863143920898,\n",
              " 83.71806740760803,\n",
              " 85.84100008010864,\n",
              " 2.056145668029785,\n",
              " 99.61256384849548,\n",
              " 98.92041683197021,\n",
              " 9.54635739326477,\n",
              " 42.31671690940857,\n",
              " 47.31400012969971,\n",
              " 0.9364426136016846,\n",
              " 79.56279516220093,\n",
              " 1.9200384616851807,\n",
              " 97.28553295135498,\n",
              " 0.27598440647125244,\n",
              " 92.73291826248169,\n",
              " 0.09572207927703857,\n",
              " 0.7430225610733032,\n",
              " 99.74209070205688,\n",
              " 87.86076307296753,\n",
              " 1.5393823385238647,\n",
              " 99.02036190032959,\n",
              " 91.10202193260193,\n",
              " 0.18919110298156738]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scV4Bm6e8zrn"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2qj25M98zro",
        "outputId": "41da4fa5-760c-4096-ae4d-939c072ddee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08o92INxMNQ0",
        "outputId": "dd1cc9fd-345a-4fed-bba8-fcefa4402314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  1 107]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN-emBmv8zrv"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhJm6re8zrv"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V5X1CAc8zry",
        "outputId": "e19e33ff-1eb4-4317-93d7-87a68094c11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdxN4orO8zr0",
        "outputId": "e9a04649-3092-4b00-9918-8b73ea8ffdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzHFt7yg8zr1",
        "outputId": "c19fe459-40f3-411b-90c6-573b271f5df2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA9-0QZgMR16",
        "outputId": "c235c26b-07b3-4e5b-989a-764657186dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-KV7kap9ER0"
      },
      "source": [
        "## ***Wine, Weather & Soil***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfFjVq0Z9ER2"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\",\"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\"],1).values"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIo8cDn9ER5"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=45)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhr3mgMMbQM"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MxQ4Kv79ER8"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z82pNgZC9ER9",
        "outputId": "4b3612be-0213-481d-9f23-835159a3fb6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.7151 - accuracy: 0.5401 - val_loss: 0.6562 - val_accuracy: 0.6473\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6825 - val_loss: 0.6028 - val_accuracy: 0.7164\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7591 - val_loss: 0.5623 - val_accuracy: 0.7236\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7810 - val_loss: 0.5363 - val_accuracy: 0.7382\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.8066 - val_loss: 0.5116 - val_accuracy: 0.7491\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.8285 - val_loss: 0.4945 - val_accuracy: 0.7382\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8467 - val_loss: 0.4762 - val_accuracy: 0.7382\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8650 - val_loss: 0.4607 - val_accuracy: 0.7455\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8723 - val_loss: 0.4427 - val_accuracy: 0.7527\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8796 - val_loss: 0.4286 - val_accuracy: 0.7782\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.8796 - val_loss: 0.4157 - val_accuracy: 0.8036\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.8869 - val_loss: 0.4076 - val_accuracy: 0.8109\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2764 - accuracy: 0.9015 - val_loss: 0.3991 - val_accuracy: 0.8182\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9124 - val_loss: 0.3869 - val_accuracy: 0.8255\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.9234 - val_loss: 0.3748 - val_accuracy: 0.8364\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9307 - val_loss: 0.3693 - val_accuracy: 0.8436\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2026 - accuracy: 0.9380 - val_loss: 0.3567 - val_accuracy: 0.8509\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1880 - accuracy: 0.9416 - val_loss: 0.3457 - val_accuracy: 0.8509\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9453 - val_loss: 0.3373 - val_accuracy: 0.8582\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1612 - accuracy: 0.9526 - val_loss: 0.3375 - val_accuracy: 0.8582\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9562 - val_loss: 0.3329 - val_accuracy: 0.8618\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9635 - val_loss: 0.3165 - val_accuracy: 0.8655\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9672 - val_loss: 0.3203 - val_accuracy: 0.8727\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9745 - val_loss: 0.3231 - val_accuracy: 0.8764\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9745 - val_loss: 0.3132 - val_accuracy: 0.8764\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9781 - val_loss: 0.3077 - val_accuracy: 0.8800\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1048 - accuracy: 0.9818 - val_loss: 0.3116 - val_accuracy: 0.8764\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9854 - val_loss: 0.3042 - val_accuracy: 0.8800\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9854 - val_loss: 0.3014 - val_accuracy: 0.8800\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9927 - val_loss: 0.3032 - val_accuracy: 0.8836\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9927 - val_loss: 0.3004 - val_accuracy: 0.8873\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9854 - val_loss: 0.2953 - val_accuracy: 0.8873\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9927 - val_loss: 0.3099 - val_accuracy: 0.8873\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9927 - val_loss: 0.2982 - val_accuracy: 0.8909\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9927 - val_loss: 0.2897 - val_accuracy: 0.8909\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9927 - val_loss: 0.2991 - val_accuracy: 0.8909\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9927 - val_loss: 0.2965 - val_accuracy: 0.8909\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9927 - val_loss: 0.3005 - val_accuracy: 0.8873\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9891 - val_loss: 0.2969 - val_accuracy: 0.8873\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9964 - val_loss: 0.2845 - val_accuracy: 0.8945\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9964 - val_loss: 0.2934 - val_accuracy: 0.8909\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9964 - val_loss: 0.2995 - val_accuracy: 0.8909\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9964 - val_loss: 0.2986 - val_accuracy: 0.8873\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9964 - val_loss: 0.2925 - val_accuracy: 0.8909\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9964 - val_loss: 0.2926 - val_accuracy: 0.8873\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9964 - val_loss: 0.2896 - val_accuracy: 0.8873\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9964 - val_loss: 0.2992 - val_accuracy: 0.8873\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9964 - val_loss: 0.3077 - val_accuracy: 0.8873\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9964 - val_loss: 0.2992 - val_accuracy: 0.8909\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9964 - val_loss: 0.2870 - val_accuracy: 0.8945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD_aJFLuMu-l",
        "outputId": "54da7908-84ae-402e-9bd5-545aa979b5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkHkpRVZ9ER_"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnZuE7rtSTA",
        "outputId": "a9c9c3bd-eff9-4c1f-fb98-51b2f1e9134b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.5532 - accuracy: 0.8415\n",
            "Loss: 0.5531876683235168, Accuracy: 0.8415300250053406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r_lF0JY9ESB"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZeAxXr7M5i9",
        "outputId": "36ab5a11-30e6-4ecb-93bc-a70c6de2dac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01052766092470847,\n",
              " 0.04734396934509277,\n",
              " 94.17247772216797,\n",
              " 0.02186298370361328,\n",
              " 0.004626305599231273,\n",
              " 99.91422891616821,\n",
              " 97.3569393157959,\n",
              " 53.62144112586975,\n",
              " 81.70475363731384,\n",
              " 7.861784100532532,\n",
              " 1.2994855642318726,\n",
              " 45.255064964294434,\n",
              " 99.6173620223999,\n",
              " 30.25517165660858,\n",
              " 2.8843194246292114,\n",
              " 0.00018012533473665826,\n",
              " 96.57665491104126,\n",
              " 95.93746662139893,\n",
              " 1.0619550943374634,\n",
              " 99.74918365478516,\n",
              " 43.07803511619568,\n",
              " 99.65671300888062,\n",
              " 92.64814257621765,\n",
              " 0.12809336185455322,\n",
              " 98.1858491897583,\n",
              " 94.20709609985352,\n",
              " 99.68259334564209,\n",
              " 82.70134925842285,\n",
              " 99.46059584617615,\n",
              " 0.00583703767915722,\n",
              " 0.15510320663452148,\n",
              " 99.99876022338867,\n",
              " 0.057253241539001465,\n",
              " 3.268405795097351,\n",
              " 34.59654450416565,\n",
              " 0.05219578742980957,\n",
              " 99.95690584182739,\n",
              " 98.42756390571594,\n",
              " 99.97795820236206,\n",
              " 0.011227592767681926,\n",
              " 89.0019178390503,\n",
              " 0.20516812801361084,\n",
              " 60.41845679283142,\n",
              " 83.46889019012451,\n",
              " 1.0040283203125,\n",
              " 99.52408075332642,\n",
              " 1.3497382402420044,\n",
              " 40.70219099521637,\n",
              " 64.11980986595154,\n",
              " 99.93064999580383,\n",
              " 3.35749089717865,\n",
              " 86.46164536476135,\n",
              " 99.62834119796753,\n",
              " 8.78884494304657,\n",
              " 99.92324709892273,\n",
              " 0.34242868423461914,\n",
              " 99.90278482437134,\n",
              " 0.16010403633117676,\n",
              " 99.66227412223816,\n",
              " 99.31210279464722,\n",
              " 98.60785007476807,\n",
              " 1.5399187803268433,\n",
              " 99.93685483932495,\n",
              " 0.054326653480529785,\n",
              " 88.3760929107666,\n",
              " 87.33097910881042,\n",
              " 37.314796447753906,\n",
              " 99.54617023468018,\n",
              " 99.07276630401611,\n",
              " 99.26308393478394,\n",
              " 41.11664295196533,\n",
              " 99.39806461334229,\n",
              " 14.392372965812683,\n",
              " 99.95700120925903,\n",
              " 1.2677192687988281,\n",
              " 99.28720593452454,\n",
              " 0.4363507032394409,\n",
              " 99.81300234794617,\n",
              " 99.34064149856567,\n",
              " 99.97882843017578,\n",
              " 21.17268145084381,\n",
              " 0.008699533645994961,\n",
              " 0.007998541695997119,\n",
              " 99.94441866874695,\n",
              " 99.602609872818,\n",
              " 0.028762221336364746,\n",
              " 0.02733767032623291,\n",
              " 85.51299571990967,\n",
              " 0.13008713722229004,\n",
              " 98.8195538520813,\n",
              " 99.87406730651855,\n",
              " 0.0287473201751709,\n",
              " 0.00012610297517312574,\n",
              " 99.92192387580872,\n",
              " 9.546306729316711,\n",
              " 98.52942824363708,\n",
              " 99.955815076828,\n",
              " 0.08533596992492676,\n",
              " 99.90262985229492,\n",
              " 99.8051106929779,\n",
              " 0.005264274659566581,\n",
              " 99.98853206634521,\n",
              " 97.91998863220215,\n",
              " 83.50733518600464,\n",
              " 99.75806474685669,\n",
              " 98.50999116897583,\n",
              " 90.39775133132935,\n",
              " 9.13340449333191,\n",
              " 99.3757963180542,\n",
              " 4.339137673377991,\n",
              " 61.263203620910645,\n",
              " 0.18381178379058838,\n",
              " 99.66113567352295,\n",
              " 1.4330506324768066,\n",
              " 99.96370077133179,\n",
              " 2.8444528579711914,\n",
              " 1.0564804077148438,\n",
              " 99.77297782897949,\n",
              " 0.03307759761810303,\n",
              " 5.246257781982422,\n",
              " 76.00141763687134,\n",
              " 64.48192596435547,\n",
              " 42.12364852428436,\n",
              " 0.5606174468994141,\n",
              " 99.94937777519226,\n",
              " 0.7595688104629517,\n",
              " 28.87885570526123,\n",
              " 0.013270974159240723,\n",
              " 91.77227020263672,\n",
              " 94.9131190776825,\n",
              " 99.04906749725342,\n",
              " 99.74977374076843,\n",
              " 99.99778270721436,\n",
              " 0.020074844360351562,\n",
              " 99.61001873016357,\n",
              " 79.98036742210388,\n",
              " 99.9995470046997,\n",
              " 0.018551945686340332,\n",
              " 83.72586369514465,\n",
              " 0.0007316005394386593,\n",
              " 98.96162748336792,\n",
              " 99.61202144622803,\n",
              " 99.99933242797852,\n",
              " 0.02028048038482666,\n",
              " 25.19097328186035,\n",
              " 99.58338737487793,\n",
              " 99.90463852882385,\n",
              " 97.28111028671265,\n",
              " 98.80024194717407,\n",
              " 0.30806660652160645,\n",
              " 99.67211484909058,\n",
              " 1.320090889930725,\n",
              " 0.0017586777175893076,\n",
              " 1.7945706844329834,\n",
              " 0.0025170977096422575,\n",
              " 94.74643468856812,\n",
              " 71.16253972053528,\n",
              " 0.006556533480761573,\n",
              " 0.5634725093841553,\n",
              " 99.79504942893982,\n",
              " 0.2514749765396118,\n",
              " 52.12993621826172,\n",
              " 85.35058498382568,\n",
              " 30.143675208091736,\n",
              " 99.88977909088135,\n",
              " 99.57380890846252,\n",
              " 38.183048367500305,\n",
              " 23.528558015823364,\n",
              " 60.85174083709717,\n",
              " 0.15994906425476074,\n",
              " 92.45070219039917,\n",
              " 3.107234835624695,\n",
              " 99.84676837921143,\n",
              " 0.011883336264872923,\n",
              " 91.6450023651123,\n",
              " 0.006023692185408436,\n",
              " 0.8683651685714722,\n",
              " 99.89506602287292,\n",
              " 99.14658069610596,\n",
              " 3.221544623374939,\n",
              " 99.94410276412964,\n",
              " 95.77158689498901,\n",
              " 0.34236013889312744]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc-m16Nr9ESK"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Td-0zH9ESK",
        "outputId": "8a6911d1-9a18-4cd0-d3bd-e8c0132bccbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xj8nt8cM-oW",
        "outputId": "ea9fb5a3-b63e-4579-810c-44bc370064f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  7 101]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfEmRyi9ESQ"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXiMrIEp9ESQ"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM1hI9zp9ESS",
        "outputId": "bf1b56f6-7de4-4e9a-a32c-4e9d0146e502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nVPSP459EST",
        "outputId": "ae7e3a9d-786a-42e2-c8d9-f73e275f2402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DZ0DjH9ESU",
        "outputId": "c1eaa002-1be0-4eb0-ffc4-7ec4c8f5b3cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkCsJSTGNDw2",
        "outputId": "6f2dafe4-38fd-45a5-eed6-8cf954c49fd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}