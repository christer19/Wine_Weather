{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library.\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import the requests library.\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for the wine API\n",
    "import urllib\n",
    "import json\n",
    "# Import the API key.\n",
    "from config import weather_api_key\n",
    "\n",
    "Token = 'tylRGHbxqiZUDNymMowCBFCuEqeULiWk'\n",
    "API_Token='Token d8f94b93417333267ca0edcca7dc14a9e035e1bb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the API key.\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'authorization': API_Token\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Wine in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_red_USA = urllib.request.Request('https://api.globalwinescore.com/globalwinescores/latest/?color=red&limit=5000&country=Usa', data=None, headers=headers, origin_req_host=None, unverifiable=False, method=None)\n",
    "res_red_USA = urllib.request.urlopen(req_red_USA).read().decode()\n",
    "obj_red_USA = json.loads(res_red_USA)\n",
    "#read json into DF\n",
    "Red_USA_df = pd.DataFrame.from_dict(obj_red_USA['results'], orient='columns')\n",
    "# To delete the column without having to reassign df you can do:\n",
    "Red_USA_df.drop([ 'wine_slug', 'appellation_slug',  'date',  'lwin', 'lwin_11'],axis=1, inplace=True)\n",
    "#'wine_id','wine_type','classification',\n",
    "#Drop NA values\n",
    "# Red_USA_df = Red_USA_df.dropna()\n",
    "#convert vintage to date type\n",
    "Red_USA_df['vintage']= pd.to_datetime(Red_USA_df['vintage']).dt.year\n",
    "Red_USA_df['regions']=Red_USA_df['regions'].str.get(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Wine in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_white_USA = urllib.request.Request('https://api.globalwinescore.com/globalwinescores/latest/?color=white&limit=5000&country=Usa', data=None, headers=headers, origin_req_host=None, unverifiable=False, method=None)\n",
    "res_white_USA = urllib.request.urlopen(req_white_USA).read().decode()\n",
    "obj_white_USA = json.loads(res_white_USA)\n",
    "#read json into DF\n",
    "white_USA_df = pd.DataFrame.from_dict(obj_white_USA['results'], orient='columns')\n",
    "# To delete the column without having to reassign df you can do:\n",
    "white_USA_df.drop([ 'wine_slug', 'appellation_slug',  'date',  'lwin', 'lwin_11'],axis=1, inplace=True)\n",
    "#'wine_id','wine_type','classification',\n",
    "#Drop NA values\n",
    "# white_USA_df = white_USA_df.dropna()\n",
    "#convert vintage to date type\n",
    "white_USA_df['vintage']= pd.to_datetime(white_USA_df['vintage']).dt.year\n",
    "white_USA_df['regions']=white_USA_df['regions'].str.get(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#California_GHCND:\n",
    "Nappa_Valley_g='GHCND:USC00046074'\n",
    "# Washington_GHCND:\n",
    "Walla_Walla_Valley_g='GHCND:GHCND:USC00457015'\n",
    "# Oregon_GHCND:\n",
    "Willamette_Valley_g='GHCND:USW00024232'\n",
    "\n",
    "#California_LAT:\n",
    "Nappa_Valley_lat='38.2777'\n",
    "# Washington_Lat:\n",
    "Walla_Walla_Valley_lat='46.3119'\n",
    "# Oregon_lat:\n",
    "Willamette_Valley_lat='44.905'\n",
    "\n",
    "#California_Long:\n",
    "Nappa_Valley_long='-122.2647'\n",
    "# Washington_Long:\n",
    "Walla_Walla_Valley_long= '-119.2633'\n",
    "# Oregon_Long:\n",
    "Willamette_Valley_long='-123.0011'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = (Nappa_Valley_g, Walla_Walla_Valley_g, Willamette_Valley_g)\n",
    "station_lat=(Nappa_Valley_lat, Walla_Walla_Valley_lat, Willamette_Valley_lat)\n",
    "station_long=(Nappa_Valley_long, Walla_Walla_Valley_long, Willamette_Valley_long)\n",
    "#find the weather station\n",
    "# https://www.ncdc.noaa.gov/cdo-web/datatools/findstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 2015\n"
     ]
    }
   ],
   "source": [
    "#Create average temperature\n",
    "dates_temp = []\n",
    "temps = []\n",
    "station_id=['GHCND:USC00046074','GHCND:GHCND:USC00457015','GHCND:USW00024232']\n",
    "\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(2015, 2016):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps += [item['value'] for item in avg_temps]\n",
    "\n",
    "#initialize dataframe\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime\n",
    "df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "#convert to degrees F\n",
    "df_temp['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps]\n",
    "df_temp = df_temp.set_index('date').resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 2015\n"
     ]
    }
   ],
   "source": [
    "#initialize lists to store data\n",
    "dates_prcp = []\n",
    "prcp = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(2015, 2016):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are Precipitation temperature readings\n",
    "    avg_prcp = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average Precipitation readings\n",
    "    dates_prcp += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average Precipitation from all average Precipitation readings\n",
    "    prcp += [item['value'] for item in avg_prcp]\n",
    "\n",
    "#initialize dataframe\n",
    "df_prcp = pd.DataFrame()\n",
    "\n",
    "#populate date and average Precipitation fields (cast string date to datetime\n",
    "df_prcp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp]\n",
    "#convert to mm to inches\n",
    "df_prcp['avgPrcp'] = [float(v)*0.0393701 for v in prcp]\n",
    "df_prcp = df_prcp.set_index('date').resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['avgPrcp']=df_prcp['avgPrcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nappa=['Nappa Valley',\n",
    "'Rutherford',\n",
    "'Oakville',\n",
    "'Howell Mountain',\n",
    "'Sonoma County',\n",
    "'Stags Leap District',\n",
    "'Russian River Valley',\n",
    "'St Helena',\n",
    "'Sonoma Coast',\n",
    "'Carneros',\n",
    "'Santa Cruz Mountains',\n",
    "'Knights Valley',\n",
    "'California',\n",
    "'Alexander Valley',\n",
    "'Spring Mountain District',\n",
    "'Dry Creek Valley',\n",
    "'Mount Veeder',\n",
    "'Yountville',\n",
    "'Diamond Mountain District',\n",
    "'Santa Lucia Highlands',\n",
    "'Green Valley',\n",
    "'Paso Robles',\n",
    "'Oak Knoll District',\n",
    "'Coombsville',\n",
    "'Santa Ynez Valley',\n",
    "'Atlas Peak',\n",
    "'Chalk Hill',\n",
    "'Amador County',\n",
    "'Calistoga',\n",
    "'Napa County',\n",
    "'Sonoma Valley',\n",
    "'Los Carneros',\n",
    "'Anderson Valley',\n",
    "'Bennett Valley',\n",
    "'Mendocino Ridge',\n",
    "'St Rita Hills',\n",
    "'Monterey',\n",
    "'Monticello',\n",
    "'Mount Harlan',\n",
    "'North Coast',\n",
    "'San Luis Obispo County',\n",
    "'Santa Mario Valley',\n",
    "'Sierra Foothills']\n",
    "\n",
    "Washington=['Walla Walla Valley',\n",
    "'Columbia Valley',\n",
    "'Red Mountain',\n",
    "'Yakima Valley',\n",
    "'Horse Heaven Hills',\n",
    "'Washington',\n",
    "'Snipes Mountains']\n",
    "\n",
    "Oregon=['Willamette Valley',\n",
    "'Dundee Hills',\n",
    "'Eola-Amity Hills',\n",
    "'Oregon',\n",
    "'Ribbon Ridge',\n",
    "'Chehalem Mountains']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine</th>\n",
       "      <th>wine_id</th>\n",
       "      <th>appellation</th>\n",
       "      <th>color</th>\n",
       "      <th>wine_type</th>\n",
       "      <th>regions</th>\n",
       "      <th>country</th>\n",
       "      <th>classification</th>\n",
       "      <th>vintage</th>\n",
       "      <th>is_primeurs</th>\n",
       "      <th>score</th>\n",
       "      <th>confidence_index</th>\n",
       "      <th>journalist_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge Vineyards, Monte Bello Chardonnay, White...</td>\n",
       "      <td>120785</td>\n",
       "      <td>Santa Cruz Mountains</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>94.39</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stags' Leap Winery, Chardonnay, White, Napa Va...</td>\n",
       "      <td>129823</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>89.83</td>\n",
       "      <td>A+</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Phelps Vineyards, Freestone Chardonnay,...</td>\n",
       "      <td>89569</td>\n",
       "      <td>Sonoma Coast</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>90.73</td>\n",
       "      <td>C+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossbarn By Paul Hobbs, Chardonnay, White, So...</td>\n",
       "      <td>47377</td>\n",
       "      <td>Sonoma Coast</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>90.39</td>\n",
       "      <td>B+</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
       "      <td>107658</td>\n",
       "      <td>Santa Cruz Mountains</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>92.22</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                wine  wine_id  \\\n",
       "0  Ridge Vineyards, Monte Bello Chardonnay, White...   120785   \n",
       "1  Stags' Leap Winery, Chardonnay, White, Napa Va...   129823   \n",
       "2  Joseph Phelps Vineyards, Freestone Chardonnay,...    89569   \n",
       "3  Crossbarn By Paul Hobbs, Chardonnay, White, So...    47377   \n",
       "4  Mount Eden Vineyards, Chardonnay, White, Santa...   107658   \n",
       "\n",
       "            appellation  color wine_type     regions country classification  \\\n",
       "0  Santa Cruz Mountains  White       dry  California     Usa           None   \n",
       "1           Napa Valley  White       dry  California     Usa           None   \n",
       "2          Sonoma Coast  White       dry  California     Usa           None   \n",
       "3          Sonoma Coast  White       dry  California     Usa           None   \n",
       "4  Santa Cruz Mountains  White       dry  California     Usa           None   \n",
       "\n",
       "   vintage  is_primeurs  score confidence_index  journalist_count  \n",
       "0     2016        False  94.39                B                 3  \n",
       "1     2016        False  89.83               A+                 3  \n",
       "2     2016        False  90.73               C+                 4  \n",
       "3     2016        False  90.39               B+                 3  \n",
       "4     2015        False  92.22                B                 4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_USA_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in white_USA_df:\n",
    "#     if white_USA_df['regions']== 'Calfornia' and white_USA_df['vintage']== 2016:\n",
    "#         white_USA_df['March']==\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgTemp</th>\n",
       "      <th>avgPrcp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-31</th>\n",
       "      <td>59.418065</td>\n",
       "      <td>0.280671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28</th>\n",
       "      <td>62.092143</td>\n",
       "      <td>0.085771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>66.083871</td>\n",
       "      <td>0.158750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-30</th>\n",
       "      <td>64.952000</td>\n",
       "      <td>0.073491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-31</th>\n",
       "      <td>63.604516</td>\n",
       "      <td>0.247651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>69.668000</td>\n",
       "      <td>0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>73.295484</td>\n",
       "      <td>0.173990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-31</th>\n",
       "      <td>75.635484</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-30</th>\n",
       "      <td>77.396000</td>\n",
       "      <td>0.316273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-31</th>\n",
       "      <td>74.741290</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30</th>\n",
       "      <td>62.372000</td>\n",
       "      <td>0.020997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>56.706452</td>\n",
       "      <td>0.289561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              avgTemp   avgPrcp\n",
       "date                           \n",
       "2015-01-31  59.418065  0.280671\n",
       "2015-02-28  62.092143  0.085771\n",
       "2015-03-31  66.083871  0.158750\n",
       "2015-04-30  64.952000  0.073491\n",
       "2015-05-31  63.604516  0.247651\n",
       "2015-06-30  69.668000  0.003937\n",
       "2015-07-31  73.295484  0.173990\n",
       "2015-08-31  75.635484  0.000000\n",
       "2015-09-30  77.396000  0.316273\n",
       "2015-10-31  74.741290  0.012700\n",
       "2015-11-30  62.372000  0.020997\n",
       "2015-12-31  56.706452  0.289561"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine</th>\n",
       "      <th>wine_id</th>\n",
       "      <th>appellation</th>\n",
       "      <th>color</th>\n",
       "      <th>wine_type</th>\n",
       "      <th>regions</th>\n",
       "      <th>country</th>\n",
       "      <th>classification</th>\n",
       "      <th>vintage</th>\n",
       "      <th>is_primeurs</th>\n",
       "      <th>score</th>\n",
       "      <th>confidence_index</th>\n",
       "      <th>journalist_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge Vineyards, Monte Bello Chardonnay, White...</td>\n",
       "      <td>120785</td>\n",
       "      <td>Santa Cruz Mountains</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>94.39</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aubert Wines, Larry Hyde &amp; Sons Vineyard Chard...</td>\n",
       "      <td>6880</td>\n",
       "      <td>Carneros</td>\n",
       "      <td>White</td>\n",
       "      <td>dry</td>\n",
       "      <td>California</td>\n",
       "      <td>Usa</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>96.98</td>\n",
       "      <td>B+</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 wine  wine_id  \\\n",
       "0   Ridge Vineyards, Monte Bello Chardonnay, White...   120785   \n",
       "13  Aubert Wines, Larry Hyde & Sons Vineyard Chard...     6880   \n",
       "\n",
       "             appellation  color wine_type     regions country classification  \\\n",
       "0   Santa Cruz Mountains  White       dry  California     Usa           None   \n",
       "13              Carneros  White       dry  California     Usa           None   \n",
       "\n",
       "    vintage  is_primeurs  score confidence_index  journalist_count  \n",
       "0      2016        False  94.39                B                 3  \n",
       "13     2016        False  96.98               B+                 3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_white_USA_df=white_USA_df.sort_values(by=['vintage'], ascending=False)\n",
    "sorted_white_USA_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e5eafaa7d675>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlist_wines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhite_USA_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhite_USA_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvintage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlist_wines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Region'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Vintage'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlist_wines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "list_wines=[]\n",
    "for i,j in zip(white_USA_df.regions, white_USA_df.vintage):\n",
    "    list_wines.append({'Region':i}, {'Vintage':j})\n",
    "list_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'California': [2016,\n",
       "  2016,\n",
       "  2016,\n",
       "  2016,\n",
       "  2015,\n",
       "  2016,\n",
       "  2016,\n",
       "  2015,\n",
       "  1993,\n",
       "  1998,\n",
       "  2016,\n",
       "  2016,\n",
       "  2015,\n",
       "  2016,\n",
       "  2015,\n",
       "  2016,\n",
       "  2016,\n",
       "  2016,\n",
       "  2015,\n",
       "  2016,\n",
       "  2016,\n",
       "  2007,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2014,\n",
       "  2016,\n",
       "  2011,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2016,\n",
       "  2016,\n",
       "  2016,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2014,\n",
       "  2015,\n",
       "  2016,\n",
       "  2014,\n",
       "  2013,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2016,\n",
       "  2014,\n",
       "  2014,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2013,\n",
       "  2013,\n",
       "  2015,\n",
       "  2015,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2015,\n",
       "  2009,\n",
       "  2014,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2015,\n",
       "  2014,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2015,\n",
       "  2015,\n",
       "  2013,\n",
       "  2015,\n",
       "  2015,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2015,\n",
       "  2015,\n",
       "  2015,\n",
       "  2010,\n",
       "  2012,\n",
       "  2014,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2010,\n",
       "  2013,\n",
       "  2014,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2013,\n",
       "  2014,\n",
       "  2006,\n",
       "  2014,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2012,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2013,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2001,\n",
       "  2009,\n",
       "  2013,\n",
       "  2012,\n",
       "  2010,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2014,\n",
       "  2013,\n",
       "  2012,\n",
       "  2008,\n",
       "  2014,\n",
       "  2009,\n",
       "  2007,\n",
       "  2008,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2010,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2013,\n",
       "  2002,\n",
       "  2012,\n",
       "  2012,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2004,\n",
       "  2013,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2005,\n",
       "  2009,\n",
       "  2007,\n",
       "  2009,\n",
       "  2008,\n",
       "  2001,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2010,\n",
       "  2001,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2011,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2011,\n",
       "  2010,\n",
       "  2012,\n",
       "  2012,\n",
       "  2007,\n",
       "  2011,\n",
       "  2010,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2013,\n",
       "  2012,\n",
       "  2012,\n",
       "  2011,\n",
       "  2009,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2013,\n",
       "  2009,\n",
       "  2011,\n",
       "  2012,\n",
       "  2010,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2012,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2012,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2011,\n",
       "  2010,\n",
       "  2011,\n",
       "  2010,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2010,\n",
       "  2010,\n",
       "  2010,\n",
       "  2011,\n",
       "  2011,\n",
       "  2010,\n",
       "  2011,\n",
       "  2010,\n",
       "  2011,\n",
       "  2010,\n",
       "  2010,\n",
       "  2012,\n",
       "  2011,\n",
       "  2010,\n",
       "  2009,\n",
       "  2009,\n",
       "  2005,\n",
       "  2010,\n",
       "  2006,\n",
       "  2011,\n",
       "  2011,\n",
       "  2012,\n",
       "  2012,\n",
       "  2010,\n",
       "  2010,\n",
       "  2010,\n",
       "  2011,\n",
       "  2010,\n",
       "  2011,\n",
       "  2011,\n",
       "  2011,\n",
       "  1999,\n",
       "  2009,\n",
       "  2010,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2011,\n",
       "  2010,\n",
       "  2010,\n",
       "  2010,\n",
       "  2010,\n",
       "  2011,\n",
       "  2010,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2010,\n",
       "  2009,\n",
       "  2009,\n",
       "  2010,\n",
       "  2009,\n",
       "  2010,\n",
       "  2009,\n",
       "  2008,\n",
       "  2010,\n",
       "  2009,\n",
       "  2006,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2008,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2008,\n",
       "  2009,\n",
       "  2000,\n",
       "  2008,\n",
       "  2009,\n",
       "  2009,\n",
       "  2009,\n",
       "  2008,\n",
       "  2009,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2007,\n",
       "  2008,\n",
       "  2009,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2009,\n",
       "  2008,\n",
       "  2008,\n",
       "  2008,\n",
       "  2007,\n",
       "  2009,\n",
       "  2008,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2008,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2007,\n",
       "  2008,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2006,\n",
       "  2007,\n",
       "  2008,\n",
       "  2007,\n",
       "  2005,\n",
       "  2006,\n",
       "  2004,\n",
       "  2007,\n",
       "  1998,\n",
       "  2006,\n",
       "  2007,\n",
       "  2007,\n",
       "  2007,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2005,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2007,\n",
       "  2006,\n",
       "  2006,\n",
       "  2007,\n",
       "  2005,\n",
       "  2006,\n",
       "  2005,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2006,\n",
       "  2005,\n",
       "  2006,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2006,\n",
       "  2005,\n",
       "  2006,\n",
       "  2003,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  1996,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2005,\n",
       "  2004,\n",
       "  2004,\n",
       "  2005,\n",
       "  2005,\n",
       "  2004,\n",
       "  2003,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2004,\n",
       "  2005,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2001,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2003,\n",
       "  2004,\n",
       "  2004,\n",
       "  2003,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2004,\n",
       "  2003,\n",
       "  2004,\n",
       "  2003,\n",
       "  2004,\n",
       "  2004,\n",
       "  2004,\n",
       "  2003,\n",
       "  2004,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2004,\n",
       "  2003,\n",
       "  2001,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2002,\n",
       "  2003,\n",
       "  2002,\n",
       "  2002,\n",
       "  2003,\n",
       "  2003,\n",
       "  2003,\n",
       "  2002,\n",
       "  2003,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2001,\n",
       "  2003,\n",
       "  2002,\n",
       "  2001,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  2002,\n",
       "  1996,\n",
       "  2002,\n",
       "  2002,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2001,\n",
       "  2002,\n",
       "  2001,\n",
       "  2000,\n",
       "  2001,\n",
       "  2000,\n",
       "  2001,\n",
       "  2000,\n",
       "  2000,\n",
       "  2001,\n",
       "  2001,\n",
       "  2002,\n",
       "  2000,\n",
       "  1993,\n",
       "  2001,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  1992,\n",
       "  2000,\n",
       "  2001,\n",
       "  2001,\n",
       "  1999,\n",
       "  2001,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  2000,\n",
       "  2000,\n",
       "  2000,\n",
       "  1999,\n",
       "  1999,\n",
       "  2000,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1998,\n",
       "  1998,\n",
       "  1998,\n",
       "  1999,\n",
       "  1998,\n",
       "  1998,\n",
       "  1998,\n",
       "  2000,\n",
       "  1999,\n",
       "  2000,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1997,\n",
       "  1997,\n",
       "  1998,\n",
       "  1998,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1998,\n",
       "  1998,\n",
       "  1999,\n",
       "  1999,\n",
       "  1999,\n",
       "  1998,\n",
       "  1999,\n",
       "  1998,\n",
       "  1998,\n",
       "  1997,\n",
       "  1998,\n",
       "  1998,\n",
       "  1998,\n",
       "  1998,\n",
       "  1998,\n",
       "  1998,\n",
       "  1997,\n",
       "  1997,\n",
       "  1998,\n",
       "  1997,\n",
       "  1998,\n",
       "  1997,\n",
       "  1997,\n",
       "  1998,\n",
       "  1998,\n",
       "  1997,\n",
       "  1997,\n",
       "  1997,\n",
       "  1996,\n",
       "  1995,\n",
       "  1997,\n",
       "  1997,\n",
       "  1996,\n",
       "  1997,\n",
       "  1996,\n",
       "  1997,\n",
       "  1997,\n",
       "  1996,\n",
       "  1996,\n",
       "  1996,\n",
       "  1996,\n",
       "  1996,\n",
       "  1996,\n",
       "  1995,\n",
       "  1996,\n",
       "  1993],\n",
       " 'Oregon': [2014,\n",
       "  2014,\n",
       "  2015,\n",
       "  2015,\n",
       "  2013,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2014,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2013,\n",
       "  2012,\n",
       "  2012,\n",
       "  2013,\n",
       "  2007,\n",
       "  2012,\n",
       "  2012,\n",
       "  2012,\n",
       "  2010,\n",
       "  2002,\n",
       "  2011,\n",
       "  2011,\n",
       "  2010,\n",
       "  2010,\n",
       "  2009,\n",
       "  2007,\n",
       "  2003,\n",
       "  1999,\n",
       "  1999],\n",
       " 'Washington': [2015,\n",
       "  2015,\n",
       "  2014,\n",
       "  2013,\n",
       "  2012,\n",
       "  2011,\n",
       "  2010,\n",
       "  2009,\n",
       "  2008,\n",
       "  2007,\n",
       "  2006,\n",
       "  2005,\n",
       "  2005,\n",
       "  2005,\n",
       "  2004,\n",
       "  2003,\n",
       "  2002,\n",
       "  2000,\n",
       "  1999,\n",
       "  1997,\n",
       "  1996]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=white_USA_df.groupby('regions')['vintage'].apply(list).to_dict()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Avg Temp and Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-41786419dd5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#get all items in the response which are average temperature readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mavg_temps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'TAVG'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m#get the date field from all average temperature readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdates_temp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavg_temps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "#Create average temperature\n",
    "dates_temp = []\n",
    "temps = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(1992, 2017):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps += [item['value'] for item in avg_temps]\n",
    "\n",
    "#initialize dataframe\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime\n",
    "df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "#convert to degrees F\n",
    "df_temp['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps]\n",
    "df_temp = df_temp.set_index('date').resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n"
     ]
    }
   ],
   "source": [
    "#initialize lists to store data\n",
    "dates_prcp = []\n",
    "prcp = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(1992, 2016):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are Precipitation temperature readings\n",
    "    avg_prcp = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average Precipitation readings\n",
    "    dates_prcp += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average Precipitation from all average Precipitation readings\n",
    "    prcp += [item['value'] for item in avg_prcp]\n",
    "\n",
    "#initialize dataframe\n",
    "df_prcp = pd.DataFrame()\n",
    "\n",
    "#populate date and average Precipitation fields (cast string date to datetime\n",
    "df_prcp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp]\n",
    "#convert to mm to inches\n",
    "df_prcp['avgPrcp'] = [float(v)*0.0393701 for v in prcp]\n",
    "df_prcp = df_prcp.set_index('date').resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
