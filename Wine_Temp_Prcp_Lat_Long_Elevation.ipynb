{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library.\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import the requests library.\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for the wine API\n",
    "import urllib\n",
    "import json\n",
    "# Import the API key.\n",
    "from config import weather_api_key\n",
    "import calendar\n",
    "\n",
    "Token = 'tylRGHbxqiZUDNymMowCBFCuEqeULiWk'\n",
    "API_Token='Token d8f94b93417333267ca0edcca7dc14a9e035e1bb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the API key.\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'authorization': API_Token\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Wine in USA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Red_USA_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5a2d115bb920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m##'wine_id','wine_type','classification',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m##Drop NA values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mRed_USA_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRed_USA_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#convert vintage to date type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mred_USA_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vintage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mred_USA_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vintage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Red_USA_df' is not defined"
     ]
    }
   ],
   "source": [
    "#import JSON data with the API\n",
    "req_red_USA = urllib.request.Request('https://api.globalwinescore.com/globalwinescores/latest/?color=red&limit=5000&country=Usa', data=None, headers=headers, origin_req_host=None, unverifiable=False, method=None)\n",
    "res_red_USA = urllib.request.urlopen(req_red_USA).read().decode()\n",
    "obj_red_USA = json.loads(res_red_USA)\n",
    "#read json into DF\n",
    "red_USA_df = pd.DataFrame.from_dict(obj_red_USA['results'], orient='columns')\n",
    "# Delete unnecessary columns\n",
    "red_USA_df.drop([ 'wine_slug', 'appellation_slug',  'date',  'lwin', 'lwin_11'],axis=1, inplace=True)\n",
    "##'wine_id','wine_type','classification',\n",
    "##Drop NA values\n",
    "Red_USA_df = Red_USA_df.dropna()\n",
    "#convert vintage to date type\n",
    "red_USA_df['vintage']= pd.to_datetime(red_USA_df['vintage']).dt.year\n",
    "red_USA_df['regions']=red_USA_df['regions'].str.get(0)\n",
    "# Read the DF to a csv\n",
    "red_USA_df.to_csv(\"Red_Wine_USA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Wine in USA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import JSON data with the API\n",
    "req_white_USA = urllib.request.Request('https://api.globalwinescore.com/globalwinescores/latest/?color=white&limit=5000&country=Usa', data=None, headers=headers, origin_req_host=None, unverifiable=False, method=None)\n",
    "res_white_USA = urllib.request.urlopen(req_white_USA).read().decode()\n",
    "obj_white_USA = json.loads(res_white_USA)\n",
    "#read json into DF\n",
    "white_USA_df = pd.DataFrame.from_dict(obj_white_USA['results'], orient='columns')\n",
    "# Delete unnecessary columns\n",
    "white_USA_df.drop([ 'wine_slug', 'appellation_slug',  'date',  'lwin', 'lwin_11'],axis=1, inplace=True)\n",
    "##'wine_id','wine_type','classification',\n",
    "##Drop NA values\n",
    "white_USA_df = white_USA_df.dropna()\n",
    "#convert vintage to date type\n",
    "white_USA_df['vintage']= pd.to_datetime(white_USA_df['vintage']).dt.year\n",
    "white_USA_df['regions']=white_USA_df['regions'].str.get(0)\n",
    "# Read the DF to a csv\n",
    "white_USA_df.to_csv(\"White_Wine_USA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Avg Temp and Precipitation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average temperature\n",
    "\n",
    "# Create empty lists to append the data into\n",
    "dates_temp = []\n",
    "temps = []\n",
    "dates_prcp = []\n",
    "prcp = []\n",
    "\n",
    "#Identify what years we want Temp and Prcp data for\n",
    "for year in range(2013, 2017):\n",
    "    year = str(year)\n",
    "    #Print out 'working on year' to idenfity if script is running correctly\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call for temp and precipitation\n",
    "    r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #Load JSON data\n",
    "    d = json.loads(r.text)\n",
    "    e = json.loads(p.text)\n",
    "    #Get TAVG and PRCP data\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp += [item['date'] for item in avg_temps]\n",
    "    dates_prcp += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps += [item['value'] for item in avg_temps]\n",
    "    prcp += [item['value'] for item in avg_prcp]\n",
    "    \n",
    "# initialize dataframe\n",
    "df_temp = pd.DataFrame()\n",
    "df_prcp = pd.DataFrame()\n",
    "\n",
    "# populate date and average temperature fields (cast string date to datetime)\n",
    "df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "df_prcp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp]\n",
    "# convert to degrees F\n",
    "df_temp['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps]\n",
    "#convert to mm to inches\n",
    "df_prcp['avgPrcp'] = [float(v)*0.0393701 for v in prcp]\n",
    "# Average the temp/prcp per day to temp/prcp per month\n",
    "df_temp = df_temp.set_index('date').resample('M').mean()\n",
    "df_prcp = df_prcp.set_index('date').resample('M').mean()\n",
    "# Combine the series into a df\n",
    "df_temp['avgPrcp']=df_prcp['avgPrcp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington Avg Temp and Precipitation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average temperature\n",
    "dates_temp_W = []\n",
    "temps_W = []\n",
    "dates_prcp_W = []\n",
    "prcp_W = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(2013, 2017):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call for temp and precipitation\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #Load JSON data\n",
    "    d = json.loads(r.text)\n",
    "    e = json.loads(p.text)\n",
    "    #Get TAVG and PRCP data\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp_W += [item['date'] for item in avg_temps]\n",
    "    dates_prcp_W += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps_W += [item['value'] for item in avg_temps]\n",
    "    prcp_W  += [item['value'] for item in avg_prcp]\n",
    "\n",
    "#initialize dataframe\n",
    "df_temp_W = pd.DataFrame()\n",
    "df_prcp_W = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime\n",
    "df_temp_W['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp_W]\n",
    "df_prcp_W['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp_W]\n",
    "#convert to degrees F\n",
    "df_temp_W['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps_W]\n",
    "#convert to mm to inches\n",
    "df_prcp_W['avgPrcp'] = [float(v)*0.0393701 for v in prcp_W]\n",
    "# Average the temp/prcp per day to temp/prcp per month\n",
    "df_temp_W = df_temp_W.set_index('date').resample('M').mean()\n",
    "df_prcp_W = df_prcp_W.set_index('date').resample('M').mean()\n",
    "# Combine the series into a df\n",
    "df_temp_W['avgPrcp']=df_prcp_W['avgPrcp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Oregon Avg Temp and Precipitation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average temperature\n",
    "dates_temp_O = []\n",
    "temps_O = []\n",
    "dates_prcp_O = []\n",
    "prcp_O = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(2013, 2017):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    e = json.loads(p.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp_O += [item['date'] for item in avg_temps]\n",
    "    dates_prcp_O += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps_O += [item['value'] for item in avg_temps]\n",
    "    prcp_O += [item['value'] for item in avg_prcp]\n",
    "\n",
    "#initialize dataframe\n",
    "df_temp_O = pd.DataFrame()\n",
    "df_prcp_O = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime\n",
    "df_temp_O['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp_O]\n",
    "df_prcp_O['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp_O]\n",
    "#convert to degrees F\n",
    "df_temp_O['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps_O]\n",
    "#convert to mm to inches\n",
    "df_prcp_O['avgPrcp'] = [float(v)*0.0393701 for v in prcp_O]\n",
    "# Average the temp/prcp per day to temp/prcp per month\n",
    "df_temp_O = df_temp_O.set_index('date').resample('M').mean()\n",
    "df_prcp_O = df_prcp_O.set_index('date').resample('M').mean()\n",
    "# Combine the series into a df\n",
    "df_temp_O['avgPrcp']=df_prcp_O['avgPrcp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Lat/Long/Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns for Lat/Long/Elevation for the red and white white data\n",
    "#There are three clusters of wineries. \n",
    "#The wineries in California, Washington, and Oregon are within a couple dozen miles of one another in each state.\n",
    "#So I just used three stations: One for California, one for Washington, one for Oregon\n",
    "\n",
    "\n",
    "#-------------------------------------------------------Station IDs---------------------------------------------------#\n",
    "#California_GHCND:\n",
    "Nappa_Valley_g='GHCND:USC00046074'\n",
    "# Washington_GHCND:\n",
    "Walla_Walla_Valley_g='GHCND:GHCND:USC00457015'\n",
    "# Oregon_GHCND:\n",
    "Willamette_Valley_g='GHCND:USW00024232'\n",
    "#--------------------------------------------------------Latitude-----------------------------------------------------#\n",
    "\n",
    "#Latitude\n",
    "#California_LAT:\n",
    "Cali_lat='38.2777'\n",
    "# Oregon_lat:\n",
    "Oregon_lat='44.905'\n",
    "# Washington_Lat:\n",
    "Washington_lat='46.3119'\n",
    "\n",
    "\n",
    "#Create a new column in red_USA_df that has latitude for california, washingtion, oregon\n",
    "latitude=[]\n",
    "for lat in red_USA_df['regions']:\n",
    "#California\n",
    "    if lat =='California':\n",
    "        latitude.append(Cali_lat)\n",
    "#Oregon\n",
    "    elif lat == 'Oregon':\n",
    "        latitude.append(Oregon_lat)\n",
    "#Washington\n",
    "    else:\n",
    "        latitude.append(Washington_lat)\n",
    "red_USA_df['lat']=latitude\n",
    "\n",
    "#Create a new column in white_USA_df that has latitude for california, washingtion, oregon\n",
    "latitude=[]\n",
    "for lat in white_USA_df['regions']:\n",
    "#California\n",
    "    if lat =='California':\n",
    "        latitude.append(Cali_lat)\n",
    "#Oregon\n",
    "    elif lat == 'Oregon':\n",
    "        latitude.append(Oregon_lat)\n",
    "#Washington\n",
    "    else:\n",
    "        latitude.append(Washington_lat)\n",
    "white_USA_df['lat']=latitude\n",
    "\n",
    "#------------------------------------------------------Longitude-------------------------------------------------------------#\n",
    "\n",
    "#Longitude\n",
    "#California_Long:\n",
    "Cali_long='-122.2647'\n",
    "# Oregon_Long:\n",
    "Oregon_long='-123.0011'\n",
    "# Washington_Long:\n",
    "Washington_long= '-119.2633'\n",
    "\n",
    "#Create a new column in red_USA_df that has longitude for california, washingtion, oregon\n",
    "longitude=[]\n",
    "for long in red_USA_df['regions']:\n",
    "#California\n",
    "    if long =='California':\n",
    "        longitude.append(Cali_long)\n",
    "#Oregon\n",
    "    elif long == 'Oregon':\n",
    "        longitude.append(Oregon_long)\n",
    "#Washington\n",
    "    else:\n",
    "        longitude.append(Washington_long)\n",
    "red_USA_df['long']=longitude \n",
    "\n",
    "#Create a new column in white_USA_df that has longitude for california, washingtion, oregon\n",
    "longitude=[]\n",
    "for long in white_USA_df['regions']:\n",
    "#California\n",
    "    if long =='California':\n",
    "        longitude.append(Cali_long)\n",
    "#Oregon\n",
    "    elif long == 'Oregon':\n",
    "        longitude.append(Oregon_long)\n",
    "#Washington\n",
    "    else:\n",
    "        longitude.append(Washington_long)\n",
    "white_USA_df['long']=longitude \n",
    "\n",
    "#-----------------------------------------------------------------Elevation------------------------------------------------#\n",
    "\n",
    "#Elevation (feet)\n",
    "#California_Elevation:\n",
    "Cali_ele='35.1'\n",
    "# Oregon_Elevation:\n",
    "Oregon_ele='205.1'\n",
    "# Washington_Elevation:\n",
    "Washington_ele= '631.9'\n",
    "\n",
    "\n",
    "#Create a new column in red_USA_df that has elevation for california, washingtion, oregon\n",
    "elevation=[]\n",
    "for ele in red_USA_df['regions']:\n",
    "#California\n",
    "    if ele =='California':\n",
    "        elevation.append(Cali_ele)\n",
    "#Oregon\n",
    "    elif ele == 'Oregon':\n",
    "        elevation.append(Oregon_ele)\n",
    "#Washington\n",
    "    else:\n",
    "        elevation.append(Washington_ele)\n",
    "red_USA_df['elevation']=elevation\n",
    "\n",
    "#Create a new column in white_USA_df that has elevation for california, washingtion, oregon\n",
    "elevation=[]\n",
    "for ele in white_USA_df['regions']:\n",
    "#California\n",
    "    if ele =='California':\n",
    "        elevation.append(Cali_ele)\n",
    "#Oregon\n",
    "    elif ele == 'Oregon':\n",
    "        elevation.append(Oregon_ele)\n",
    "#Washington\n",
    "    else:\n",
    "        elevation.append(Washington_ele)\n",
    "white_USA_df['elevation']=elevation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_USA_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Temp/Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the date into columns for days, months, years and then drop days columns for each of the three states\n",
    "#-------------------------------------------------------------------------------California----------------------------\n",
    "df_temp.reset_index(inplace= True )\n",
    "df_temp['day'] = df_temp['date'].dt.day\n",
    "df_temp['month'] = df_temp['date'].dt.month\n",
    "df_temp['year'] = df_temp['date'].dt.year\n",
    "\n",
    "list_months=[]\n",
    "for x in df_temp['month']:\n",
    "    list_months.append(calendar.month_name[x])\n",
    "df_temp['months']=list_months\n",
    "df_temp.drop(['date', 'day','month'], axis=1, inplace=True)\n",
    "#----------------------------------------------------------------------------------Oregon-------------------------------\n",
    "df_temp_O.reset_index(inplace= True )\n",
    "df_temp_O['day'] = df_temp_O['date'].dt.day\n",
    "df_temp_O['month'] = df_temp_O['date'].dt.month\n",
    "df_temp_O['year'] = df_temp_O['date'].dt.year\n",
    "\n",
    "list_months=[]\n",
    "for x in df_temp_O['month']:\n",
    "    list_months.append(calendar.month_name[x])\n",
    "df_temp_O['months']=list_months\n",
    "df_temp_O.drop(['date', 'day','month'], axis=1, inplace=True)\n",
    "#-----------------------------------------------------------------------------------Washington---------------------\n",
    "df_temp_W.reset_index(inplace= True )\n",
    "df_temp_W['day'] = df_temp_W['date'].dt.day\n",
    "df_temp_W['month'] = df_temp_W['date'].dt.month\n",
    "df_temp_W['year'] = df_temp_W['date'].dt.year\n",
    "\n",
    "list_months=[]\n",
    "for x in df_temp_W['month']:\n",
    "    list_months.append(calendar.month_name[x])\n",
    "df_temp_W['months']=list_months\n",
    "df_temp_W.drop(['date', 'day','month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_USA_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # .apply() method\n",
    "# white_USA_df['march']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying to add columns for weather data for each month\n",
    "\n",
    "# list_temp_march=[]\n",
    "# def monthData (year, month, region, vintage):\n",
    "#     for u,v,x,y,z in zip(white_USA_df['regions'],white_USA_df['vintage'],df_temp['year'], df_temp['avgTemp'], df_temp['months']):\n",
    "#         if v==x and v==2016 and u=='California'and z=='March':\n",
    "#             list_temp_march.append(y)\n",
    "#     #     elif y==z and y==2016 and x=='Oregon'and v=='April':\n",
    "#     #         list_temp_march.append(u)\n",
    "#         else:\n",
    "#             list_temp_march.append(0)\n",
    "# white_USA_df['march']=white_USA_df['march'].apply(monthData)\n",
    "# white_USA_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_white_USA_df=white_USA_df.sort_values(by=['regions'], ascending=False)\n",
    "# sorted_white_USA_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported dependencies<p>\n",
    "Used the Global Wine Score API to import data for red and white wine in the USA<p>\n",
    "Imported weather data for California, Oregon, Washington<p>\n",
    "Added new columns Latitude, Longitude, and Elevation to red and white wine dataframes<p>\n",
    "Finally I am trying to add new columns for monthly weather data to the red and white wine dataframes<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
